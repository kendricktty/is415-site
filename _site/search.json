[
  {
    "objectID": "HandsOn/Hands-on_Ex02/hands-on-2.html",
    "href": "HandsOn/Hands-on_Ex02/hands-on-2.html",
    "title": "H2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "While thematic mapping uses map symbols to visualise geographic properties such as population and temperature, geovisualisation is a subset of thematic mapping, where a pseudocolour is used to correspond with these geographic properties."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.1-overview",
    "href": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.1-overview",
    "title": "H2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "While thematic mapping uses map symbols to visualise geographic properties such as population and temperature, geovisualisation is a subset of thematic mapping, where a pseudocolour is used to correspond with these geographic properties."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.2-getting-started",
    "href": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.2-getting-started",
    "title": "H2: Thematic Mapping and GeoVisualisation with R",
    "section": "H2.2 Getting Started",
    "text": "H2.2 Getting Started\ntmap contains the packages needed to perform geovisualisation, so we need to import that along with the usual packages we use.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.3-importing-data-into-r",
    "href": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.3-importing-data-into-r",
    "title": "H2: Thematic Mapping and GeoVisualisation with R",
    "section": "H2.3 Importing Data into R",
    "text": "H2.3 Importing Data into R\nThe datasets to be used are:\n\nMaster Plan 2014 Subzone Boundary (Web)(MP14_SUBZONE_WEB_PL) in ESRI shapefile format\n\n\nmp_subzone &lt;- st_read(dsn = \"../data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmp_subzone\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\nunique(mp_subzone$REGION_N)\n\n[1] \"CENTRAL REGION\"    \"WEST REGION\"       \"EAST REGION\"      \n[4] \"NORTH-EAST REGION\" \"NORTH REGION\"     \n\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 (aspatial)\n\n\npopulation_data &lt;- read_csv(\"../data/aspatial/respopagesextod2011to2020/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(population_data)\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2011\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats       10  2011\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       30  2011\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    50  2011\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2011\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Landed Properties       0  2011\n\n\nThe data appears to be arranged in order of planning area, so by calling head(), the first few rows feature entries located in the good town of Ang Mo Kio."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.3.4-data-preparation",
    "href": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.3.4-data-preparation",
    "title": "H2: Thematic Mapping and GeoVisualisation with R",
    "section": "H2.3.4 Data Preparation",
    "text": "H2.3.4 Data Preparation\nTo prepare our thematic map visualising the distribution of Singapore residents of various attributes, we need to filter the population dataset to only include values from the year 2020.\n\nH2.3.4.0 %&gt;% Operator\nThe %&gt;% operator is used extensively here, so as an R beginner, it might be worth summarising what it does. Basically, %&gt;% is a pipe that directs the output of the function called to its left to the one called on its right.\n\nquadratic_function &lt;- function(x) {\n    return(x * x)\n}\n\nadd_3 &lt;- function(x) {\n    return(x + 3)\n}\n\nmultiply_2 &lt;- function(x) {\n    return(x * 2)\n}\n\nthree_plus_three_times_2 &lt;- 3 %&gt;%\n    multiply_2() %&gt;%\n    add_3() %&gt;%\n    multiply_2()\nprint(\"Expected: 18\")\n\n[1] \"Expected: 18\"\n\nprint(paste(\"Actual:\", three_plus_three_times_2, sep = \" \"))\n\n[1] \"Actual: 18\"\n\n\nThe alternative would be to create a large composite list of functions within functions, which would make our code difficult to read:\n\nthree_plus_three_times_2 &lt;- multiply_2(add_3(multiply_2(3)))\nprint(\"Expected: 18\")\n\n[1] \"Expected: 18\"\n\nprint(paste(\"Actual:\", three_plus_three_times_2, sep = \" \"))\n\n[1] \"Actual: 18\"\n\n\nIn the context of data preprocessing, the %&gt;% would be akin, in Python, to chaining multiple pandas methods together in the same line, such that the operations are also performed from left to right. For example:\ndf = pd.read_csv()\ndf.fillna().head()\n\nH2.3.4.1 Data wrangling\nGreat! Now that we’ve explained %&gt;%, let’s now move on to the more complicated job of feature-engineering the population data.\n\npopulation_2020 &lt;- population_data %&gt;%\n    filter(Time == 2020) %&gt;%\n    group_by(PA, SZ, AG) %&gt;%\n    summarise(`POP` = sum(`Pop`)) %&gt;%\n    ungroup() %&gt;%\n    pivot_wider(names_from = AG, values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(population_2020)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_over\"\n\n\n\npopulation_2020 &lt;- population_2020 %&gt;%\n    # As young boys in Singapore serve 2 years of national service, the earliest age to be considered economically active should be 25.\n    mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n    # By 2026, the retirement age in Singapore will be raised to 64.\n    mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15])) %&gt;%\n    mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n    mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n    / `ECONOMY ACTIVE`) %&gt;%\n    select(\n        `PA`, `SZ`, `YOUNG`,\n        `ECONOMY ACTIVE`, `AGED`,\n        `TOTAL`, `DEPENDENCY`\n    )\n\n\n\nH2.3.4.2 Joining attribute and geospatial data\nA georelational join will now need to be performed to combine them into the same table.\nBefore we can do so, though, we need to convert the PA and SZ fields to uppercase, to unify its presentation with teh SUBZONE_N and PLN_AREA_N fields.\n\npopulation_2020 &lt;- population_2020 %&gt;%\n    mutate_at(.vars = vars(PA, SZ), .funs = list(toupper)) %&gt;%\n    filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe can now perform a left join (from the dplyr function) between the subzone geospatial data and the population data on the SUBZONE_N and SZ identifiers:\n\ncombined &lt;- left_join(mp_subzone, population_2020, by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.4-choropleth-mapping-using-tmap",
    "href": "HandsOn/Hands-on_Ex02/hands-on-2.html#h2.4-choropleth-mapping-using-tmap",
    "title": "H2: Thematic Mapping and GeoVisualisation with R",
    "section": "H2.4 Choropleth mapping using tmap",
    "text": "H2.4 Choropleth mapping using tmap\nWe can now create our choropleth map.\nAs adapted from the course website:\n\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\n\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nH2.4.1 Plotting a choropleth map quickly using qtm()\nThe easiest and quickest way to draw a chloropleth map is using qtm():\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(combined,\n    fill = \"DEPENDENCY\"\n)\n\n\n\n\n\n\n\n\nThis map indicates that the dependency ratio in most of the island is a supposedly healthy 5 and below. Missing datapoints correspond with major commercial nodes and key installations in the country (such as Changi Airport in the east, the central catchment nature reserve, the downtown core and industrial estates in Jurong and Tuas), while Changi Village (the patch of red) seems to have the highest percentage of dependents.\n\nLearning points:\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\n\n\n\n\nfill argument is used to map the attribute (in this case, \"DEPENDENCY\")\n\n\n\n\nH2.4.2 Creating a choropleth map using tmap elements\nA major disadvantage of qtm() is that it makes aesthetics of individual layers harder to control. Using the tmap elements allows us to draw better quality cartographic choropleth maps like the one below.\n\ntm_shape(combined) +\n    tm_fill(\"DEPENDENCY\",\n        style = \"quantile\",\n        palette = \"Blues\",\n        title = \"Dependency ratio\"\n    ) +\n    tm_layout(\n        main.title = \"Distribution of Dependency Ratio by planning subzone\",\n        main.title.position = \"center\",\n        main.title.size = 1.2,\n        legend.height = 0.45,\n        legend.width = 0.35,\n        frame = TRUE\n    ) +\n    tm_borders(alpha = 0.5) +\n    tm_compass(type = \"8star\", size = 2) +\n    tm_scale_bar() +\n    tm_grid(alpha = 0.2) +\n    tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n        position = c(\"left\", \"bottom\")\n    )\n\n\n\n\n\n\n\n\nOnce again the missing datapoints correspond to areas of the country not dedicated to residential use, but this time we have a much more varied visualisation of the dependency ratio within the country. The areas with the highest dependency ratio appear to correlate with the oldest HDB estates, from Toa Payoh to Queenstown, while the newer estates such as Sengkang, Punggol and even Yishun have a smaller proportion of dependents.\n\nH2.4.2.1 Drawing a base map\nIn the code chunk below, tm_shape() is used to define the input data (i.e comined) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(combined) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign that target variable to tm_polgyons(). The maps below show higher than usual populations of young dependents in Woodlands, Sengkang, Punggol, Tampines and Pasir Ris, and higher than usual populations of elderly dependents in Ang Mo Kio, Hougang and Bedok.\n\ntm_shape(combined) + tm_polygons(\"YOUNG\")\n\n\n\n\n\n\n\ntm_shape(combined) + tm_polygons(\"AGED\")\n\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, missing values are shaded in grey.\n\n\n\nH2.4.2.3 Drawing a choropleth map with tm_fill() and tm_border()\ntm_polygons() is a wrapper of tm_fill() and tm_border(), which shades the polygons and adds borders from the shapefile onto the map respectively. Let’s see what happens when we try to use each of these two functions individually:\n\ntm_shape(combined) + tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\ntm_shape(combined) + tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\ntm_shape(combined) + tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument is used to define a transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nThe three other arguments for tm_borders() are:\n\ncol: border colour\nlwd: border line width (default 1)\nlty: border line type (default solid)\n\n\n\n\nH2.4.3 Data classification methods of tmap\nData classification serves to take a large number of observations and group them into data ranges or classes. tmap provides a total ten data classification methods, namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks. A data classification method is defined using the style argument of the tm_fill() or tm_polygons() method.\n\nH2.4.3.1 Plotting choropleth maps with built-in classification methods\nA quantile data classification with 4 classes:\n\ntm_shape(combined) +\n    tm_fill(\"AGED\",\n        n = 4,\n        style = \"quantile\"\n    ) +\n    tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAn equal data classification:\n\ntm_shape(combined) +\n    tm_fill(\"AGED\",\n        n = 5,\n        style = \"equal\"\n    ) +\n    tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nUsing standard deviation:\n\ntm_shape(combined) +\n    tm_fill(\"AGED\",\n        n = 4,\n        style = \"sd\"\n    ) +\n    tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nUsing K-means classification with 5, 10 and 15 class sizes:\n\n# for (i in 1:3) {\n#     tm_shape(combined) +\n#         tm_fill(\"AGED\", n = (5 * i), style = \"kmeans\") +\n#         tm_borders(alpha = 0.5)\n# }\ntm_shape(combined) +\n    tm_fill(\"AGED\",\n        n = 5,\n        style = \"kmeans\"\n    ) +\n    tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(combined) +\n    tm_fill(\"AGED\",\n        n = 10,\n        style = \"kmeans\"\n    ) +\n    tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(combined) +\n    tm_fill(\"AGED\",\n        n = 15,\n        style = \"kmeans\"\n    ) +\n    tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe quantile and kmeans with higher n classifications are able to highlight the distribution of elderly dependents in Singapore the most clearly. The largest distributions of elderly dependents are clustered in the central, northeast and east of Singapore, with small pockets in the north and west.\n\n\nH2.4.3.2 Plotting choropleth maps with custom breaks\nCategory breaks in the built-in styles are calculated automatically. We can override the default breaks by using the breaks argument in tm_fill() to set our own breakpoints.\n\nIt is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\n\nBefore we move on though, it is a good practice to retrieve our variable’s descriptive statistics - mean, median, quartiles, min and max. I’m supposed to work on the DEPENDENCY feature, but because I’m interested to map the concentration of our elderly population, I will work instead on the AGED feature.\n\nsummary(combined$AGED)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0     515    2080    2667    3745   20240      92 \n\n\nWe are most interested in which regions of the country contain the range between the first and third quartiles - within which also lies the mean and median. This is a universally-understood indicator of central tendency.\nAs such, our breakpoints will be the following vector:\n\naged_breaks &lt;- c(0, 514, 2079, 2666, 3744, 20240)\n\nwhere aged_breaks[1] and aged_breaks[6] are the min and max respectively. In R, indexes start at 1, and not 0 as is the case of 0-indexed languages like Python, C or Java.\n\n\n\nH2.4.4 Colour Scheme\nWith our statistically-derived breakpoints now set, we can now move on to plotting our more statistically informed choropleth map.\nSimCity 4, which I play a lot of, plots age-related data for in-game cities using a colour ramp of green (lowest) and blue (highest). Therefore, to showcase the use of tm_fill()’s palette argument for colouring, we can define a colour vector to use to colour our map in that manner.\n\ntm_shape(combined) +\n  tm_fill(\"AGED\", breaks=aged_breaks, palette=c(\"green\", \"blue\")) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nOr we could use one of the built-in single-colour palettes as such:\n\ntm_shape(combined) +\n  tm_fill(\"AGED\", breaks=aged_breaks, palette=\"Purples\") +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, we can add a “-” prefix:\n\ntm_shape(combined) +\n  tm_fill(\"AGED\", breaks=aged_breaks, palette=\"-Oranges\") +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\nH2.4.5 Map Layouts\n\nH2.4.5.1 Map Legend\nFrom this section onward, we will revert to working on the DEPENDENCY feature.\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(combined)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Oranges\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nH2.4.5.2 Map style\nWe can also change the map style by calling tmap_style().\n\ntm_shape(combined)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\nH2.4.5.3 Cartographic furniture\nBesides map style, tmap also allows us to draw other map furniture like compasses, scale bars and grid lines. In the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add a compass, scale bar and grid lines respectively to the map.\n\ntm_shape(combined)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Greens\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nFinally, the following code chunk resets the default style.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nH2.4.6 Drawing small multiple choropleth maps\nFrom the course outline:\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\n\n\nby assigning multiple values to at least one of the asthetic arguments,\n\n\n\n\nby defining a group-by variable in tm_facets(), and\n\n\n\n\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nH2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(combined)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\ntm_shape(combined)+ \n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nH2.4.6.2 By defining a group-by variable in tm_facets()\nHelpful for separating our choropleth map by regions:\n\ntm_shape(combined) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\nH2.4.6.3 By creating multiple standalone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(combined)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(combined)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nH2.4.7 Mapping Spatial Objects meeting a selection criterion\nSometimes we may not have the screen real estate to create multiple small choropleth maps. In such a situation, we can use a selection function to map spatial objects meeting a selection criterion.\nIn the following code chunk, our selection function will map out the distribution of dependents in only the northeast region of the country.\n\ntm_shape(combined[combined$REGION_N==\"NORTH-EAST REGION\", ])+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"kmeans\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Hi there! My name is Kendrick Teo, and I’m a final-year student of Singapore Management University (SMU).\nThe purpose of this website is to document my learning journey in the course: IS415: Geospatial Analytics and Applications under professor Kam Tin Seong. Follow along with my coursework below as I explore the vast world of data analytics, geospatial analytics and urban planning.\nIf you’re liking this site so far, I would most appreciate it if you could connect with me on LinkedIn!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415: Geospatial Analytics and Applications",
    "section": "",
    "text": "Welcome, and thanks for stopping by! My name is Kendrick, and you’ve reached my portfolio website for IS415: Geospatial Analytics and Applications.\nhello_world &lt;- \"hello world!\"\nprint(hello_world)\n\n[1] \"hello world!\""
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Changelog: Since the same dataset may be required across multiple hands-on exercises, the data folder for this hands-on exercise has been moded to the root of the HandsOn directory. Correspondingly, all code chunks have been modified to reference the newly located data folder."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.4.1-importing-polygon-feature-data-in-shapefile-format",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.4.1-importing-polygon-feature-data-in-shapefile-format",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.4.1 Importing polygon feature data in shapefile format",
    "text": "H1.4.1 Importing polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\nmp_subzone = st_read(dsn=\"../data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThere are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.4.2-importing-polyline-feature-data-in-shapefile-form",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.4.2-importing-polyline-feature-data-in-shapefile-form",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.4.2 Importing polyline feature data in shapefile form",
    "text": "H1.4.2 Importing polyline feature data in shapefile form\nUsing the same method as above, we now import the CyclingPath shapefile into R as a line feature data frame.\n\ncycling_paths = st_read(dsn=\"../data/geospatial/CyclingPath_Jul2024\", layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.4.3-importing-gis-data-in-kml-format",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.4.3-importing-gis-data-in-kml-format",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.4.3 Importing GIS data in kml format",
    "text": "H1.4.3 Importing GIS data in kml format\n\npreschool_data = st_read(\"../data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.5.1-working-with-st_geometry",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.5.1-working-with-st_geometry",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.5.1 Working with st_geometry()",
    "text": "H1.5.1 Working with st_geometry()\n\nst_geometry(mp_subzone)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.5.2-working-with-glimpse",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.5.2-working-with-glimpse",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.5.2 Working with glimpse()",
    "text": "H1.5.2 Working with glimpse()\n\nglimpse(mp_subzone)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.5.3-working-with-head",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.5.3-working-with-head",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.5.3 Working with head()",
    "text": "H1.5.3 Working with head()\n\nhead(mp_subzone, n=10)\n\nSimple feature collection with 10 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 20660.53 ymin: 28369.47 xmax: 32362.39 ymax: 30684.55\nProjected CRS: SVY21\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.7.1-assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.7.1-assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.7.1 Assigning EPSG code to a simple feature data frame",
    "text": "H1.7.1 Assigning EPSG code to a simple feature data frame\nA common issue that can happen when impmorting geospatial data into R is a missing or wrongly assigned coordinate system. For example:\n\nst_crs(mp_subzone)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAt the end of the output, the EPSG code is displayed, and it reads 9001 (world). The correct EPSG code for the Singapore Plane Coordinate System (SVY21) should be 3414 (Singapore). As such, we need to assign the correct EPSG code using the following code chunk:\n\nmpsz_3414 &lt;- st_set_crs(mp_subzone, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nst_crs(mpsz_3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.7.2-transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.7.2-transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.7.2 Transforming the projection of preschool from wgs84 to svy21",
    "text": "H1.7.2 Transforming the projection of preschool from wgs84 to svy21\nAs noted in the above warning message upon applying st_set_crs(), simply replacing the EPSG code does not reproject the data.\nAs adapted from the course website:\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\n\n\nst_geometry(preschool_data)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nRunning the above code reveals the preschool featureset uses the wrong wgs84 coordinate system. To fix this, instead of running st_set_crs(), we have to run st_transform() to reproject preschool from one coordinate system to another.\n\npreschool_3414 &lt;- st_transform(preschool_data, crs=3414)\nst_geometry(preschool_3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.8.1-importing-aspatial-airbnb-data",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.8.1-importing-aspatial-airbnb-data",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.8.1 Importing aspatial Airbnb data",
    "text": "H1.8.1 Importing aspatial Airbnb data\nJust like importing and reading data in Python’s pandas, importing aspatial data into the R/quarto environment is as easy as calling read_csv().\n\nlistings &lt;- read_csv(\"../data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.8.2-creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.8.2-creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.8.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "H1.8.2 Creating a simple feature data frame from an aspatial data frame\n\nlistings_sf &lt;- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;%\n    st_transform(crs=3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore’s SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into the svy21 projected coordinates system.\n\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.9.1-buffering",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.9.1-buffering",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.9.1 Buffering",
    "text": "H1.9.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cycling_paths, dist=5, nQuadSegs=30)\n\nThen, we calculate the area of the buffers:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n…and take the sum of Base R to derive the total land needed.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.9.2-point-in-polygon-count",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.9.2-point-in-polygon-count",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.9.2 Point-in-polygon count",
    "text": "H1.9.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz_3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz_3414, preschool_3414))\n\nsummary(mpsz_3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\n\nWarning: Not to be confused by st_intersection().\n\ntop_n() from the dplyr package, for n = 1, is used to find the planning subzone with the greatest number of preschools:\n\ntop_n(mpsz_3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nDIY: Calculate the density of pre-school by planning subzone.\n\nThe solution:\nFirst, use st_area() of the sf package to derive the area of each planning subzone:\n\nmpsz_3414$Area &lt;- mpsz_3414 %&gt;%\n  st_area()\n\nNext, mutate() of the dplyr package is used to compute the density by using the code chunk below.\n\nmpsz_3414 &lt;- mpsz_3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.10.1-plotting-the-distribution-of-presch-density",
    "href": "HandsOn/Hands-on_Ex01/hands-on-1.html#h1.10.1-plotting-the-distribution-of-presch-density",
    "title": "H1: Geospatial Data Wrangling with R",
    "section": "H1.10.1 Plotting the distribution of PreSch Density",
    "text": "H1.10.1 Plotting the distribution of PreSch Density\n\nhist(mpsz_3414$`PreSch Density`)\n\n\n\n\n\n\n\n\n\nggplot(data=mpsz_3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"orange\") +\n  labs(title = \"Are preschools evenly distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single preschool. On the other hand, \\nthere are two planning sub-zones with at least 20 preschools!\",\n      x = \"Pre-school density (per km^2)\",\n      y = \"Frequency\")"
  },
  {
    "objectID": "InClass/ICE1/in-class-1.html",
    "href": "InClass/ICE1/in-class-1.html",
    "title": "CE1: Geospatial Data Science",
    "section": "",
    "text": "CE1 Overview\nThe aim of this exercise is to practise loading simple featuresets (point, line, polygon, etc) with R.\n\n\nCE1.1"
  },
  {
    "objectID": "InClass/ICE1/data/MPSZ-2019.html",
    "href": "InClass/ICE1/data/MPSZ-2019.html",
    "title": "IS415 - Kendrick",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html",
    "href": "InClass/ICE2/in-class-2.html",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "",
    "text": "Create a subfolder called data in In-class_Ex02 folder\nDownload and load both the ESRI shapefile and kml file from Master Plan 2014 Subzone Boundary (Web) from the portal.\nWrite a code chunk to import Master Plan 2014 Subzone Boundary (Web) as SF simple features DataFrame.\n\n\npacman::p_load(sf, tmap, tidyverse, ggstatsplot)\n\nmp_subzone_14_shp &lt;- st_read(dsn=\"data/MasterPlan2014SubzoneBoundaryWebSHP\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/InClass/ICE2/data/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nclass(mp_subzone_14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n#! eval:false\n# Doesn't work!\ntryCatch({mp_subzone_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")}, error=function(e) {\n  print(e)\n  print(\"Cannot load!\")\n  })\n\n&lt;Rcpp::exception: Cannot open \"/Users/kendricktty/Gits/smu_cs/is415-site/InClass/ICE2/data/MasterPlan2014SubzoneBoundaryWebKML.kml\"; The source could be corrupt or not supported. See `st_drivers()` for a list of supported formats.&gt;\n[1] \"Cannot load!\"\n\n# So we need to write our own KML file.\nst_write(mp_subzone_14_shp, \"data/WORKINGMasterPlan2014SubzoneBoundaryWebKML.kml\", delete_dsn=TRUE)\n\nDeleting source `data/WORKINGMasterPlan2014SubzoneBoundaryWebKML.kml' using driver `KML'\nWriting layer `WORKINGMasterPlan2014SubzoneBoundaryWebKML' to data source \n  `data/WORKINGMasterPlan2014SubzoneBoundaryWebKML.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n# delete_dsn replaces the file with our new one if its already exists"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html#ce2.1-working-with-masterplan-2014-subzone-data",
    "href": "InClass/ICE2/in-class-2.html#ce2.1-working-with-masterplan-2014-subzone-data",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "",
    "text": "Create a subfolder called data in In-class_Ex02 folder\nDownload and load both the ESRI shapefile and kml file from Master Plan 2014 Subzone Boundary (Web) from the portal.\nWrite a code chunk to import Master Plan 2014 Subzone Boundary (Web) as SF simple features DataFrame.\n\n\npacman::p_load(sf, tmap, tidyverse, ggstatsplot)\n\nmp_subzone_14_shp &lt;- st_read(dsn=\"data/MasterPlan2014SubzoneBoundaryWebSHP\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/InClass/ICE2/data/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nclass(mp_subzone_14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n#! eval:false\n# Doesn't work!\ntryCatch({mp_subzone_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")}, error=function(e) {\n  print(e)\n  print(\"Cannot load!\")\n  })\n\n&lt;Rcpp::exception: Cannot open \"/Users/kendricktty/Gits/smu_cs/is415-site/InClass/ICE2/data/MasterPlan2014SubzoneBoundaryWebKML.kml\"; The source could be corrupt or not supported. See `st_drivers()` for a list of supported formats.&gt;\n[1] \"Cannot load!\"\n\n# So we need to write our own KML file.\nst_write(mp_subzone_14_shp, \"data/WORKINGMasterPlan2014SubzoneBoundaryWebKML.kml\", delete_dsn=TRUE)\n\nDeleting source `data/WORKINGMasterPlan2014SubzoneBoundaryWebKML.kml' using driver `KML'\nWriting layer `WORKINGMasterPlan2014SubzoneBoundaryWebKML' to data source \n  `data/WORKINGMasterPlan2014SubzoneBoundaryWebKML.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n# delete_dsn replaces the file with our new one if its already exists"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html#ce2.2-working-with-masterplan-2019-subzone-data",
    "href": "InClass/ICE2/in-class-2.html#ce2.2-working-with-masterplan-2019-subzone-data",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "CE2.2 Working with Masterplan 2019 Subzone Data",
    "text": "CE2.2 Working with Masterplan 2019 Subzone Data\n\nmp_subzone_19_shp &lt;- st_read(dsn=\"data/MPSZ-2019\", layer=\"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/InClass/ICE2/data/MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmp_subzone_19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/InClass/ICE2/data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html#ce2.3-transforming-coordinate-data-from-wgs84-to-svy21",
    "href": "InClass/ICE2/in-class-2.html#ce2.3-transforming-coordinate-data-from-wgs84-to-svy21",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "CE2.3 Transforming coordinate data from WGS84 to SVY21",
    "text": "CE2.3 Transforming coordinate data from WGS84 to SVY21\n\nmp_subzone_19_shp &lt;- mp_subzone_19_shp %&gt;% st_transform(crs = 3414)\nst_crs(mp_subzone_19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html#ce2.4-working-with-population-data",
    "href": "InClass/ICE2/in-class-2.html#ce2.4-working-with-population-data",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "CE2.4 Working with Population Data",
    "text": "CE2.4 Working with Population Data\n\npopulation_2023 &lt;- read_csv(\"data/respopagesextod2023/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nprint(\"Columns of population_2023\")\n\n[1] \"Columns of population_2023\"\n\ncolnames(population_2023)\n\n[1] \"PA\"   \"SZ\"   \"AG\"   \"Sex\"  \"TOD\"  \"Pop\"  \"Time\"\n\nprint(\"Head of population_2023\")\n\n[1] \"Head of population_2023\"\n\nhead(population_2023)\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2023\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats        0  2023\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       10  2023\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    30  2023\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2023\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Condominiums and O…    40  2023"
  },
  {
    "objectID": "InClass/ICE2/data/MPSZ-2019/MPSZ-2019.html",
    "href": "InClass/ICE2/data/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415 - Kendrick",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html#ce2.5-group-data-by-planning-area-and-subzone",
    "href": "InClass/ICE2/in-class-2.html#ce2.5-group-data-by-planning-area-and-subzone",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "CE2.5 Group data by planning area and subzone",
    "text": "CE2.5 Group data by planning area and subzone\n\npopulation_2023_pivot &lt;- population_2023 %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP`=sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, values_from=POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(population_2023)\n\n[1] \"PA\"   \"SZ\"   \"AG\"   \"Sex\"  \"TOD\"  \"Pop\"  \"Time\"\n\n# Read the data structure carefully before proceeding!"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "",
    "text": "Notes for grading: For week 3, the requirement is to complete both chapters 4 and 5 in the R for Geospatial Data Science and Analytics course website. Both have been combined into a single webpage for brevity."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.1-overview",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.1-overview",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.1 Overview",
    "text": "H3.1 Overview\nSpatial Point Pattern Analysis serves to evaluate the pattern or distribution of a set of points on a map surface. These points serve many purposes, ranging from mapping events like crimes and disease onset (like John Snow’s map of the 1854 Broad Street cholera outbreak), or the locations of business services or facilities.\nUsing appropriate functions, this hands-on exercise aims to discover the spatial point patterns of a quintessential facility in 2020s Singapore - childcare centres. Specifically, we want to find out:\n\nif these are randomly distributed throughout the country, and;\nthe planning areas with the highest concentration of childcare centres."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.2-the-data",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.2-the-data",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.2 The data",
    "text": "H3.2 The data\nThe datasets to be used are:\n\nMP14_SUBZONE_WEB_PL, containing polygon features.\nCoastalOutline, a new dataset containing polygon features showing the boundaries of Singapore. It is provided by SLA in ESRI shapefile format.\n\nIn addition, our childcare centre data will, as always, be sourced from the Singapore government’s data lake at data.gov.sg. These will take the form of point feature data."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.3-installing-and-loading-r-packages",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.3-installing-and-loading-r-packages",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.3 Installing and Loading R packages",
    "text": "H3.3 Installing and Loading R packages\nAlong with the usual sf and tmap, three new packages will be used. They are:\n\nspatstat, which includes a wide range of useful functions for first and second order spatial point patterns analysis, and to derive the kernel density estimation (KDE) layer.\nraster reads, writes, manipulates, analyses and models (i.e. rasters) gridded spatial data.\nmaptools, which is for manipulating geographic data.\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.4-spatial-data-wrangling",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.4-spatial-data-wrangling",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.4 Spatial Data Wrangling",
    "text": "H3.4 Spatial Data Wrangling\n\nH3.4.1 Importing spatial data\nHere, we import the data we need and plot basic maps to get a basic sense of the spatial patterns we are dealing with.\n\nmpsz_sf &lt;- st_read(dsn=\"../data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nsg_sf &lt;- st_read(dsn=\"../data/geospatial/CoastalOutline\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/CoastalOutline' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nchildcare_sf &lt;- st_read(\"../data/geospatial/child-care-services-geojson.geojson\") %&gt;% st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/HandsOn/data/geospatial/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\ntm_shape(mpsz_sf) + tm_polygons() + tm_shape(childcare_sf) + tm_dots() + tm_layout(title = 'Childcare Centres')\n\n\n\n\n\n\n\n\nAlternatively, we can prepare a pin map as below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) + tm_dots() + tm_layout(title = 'Childcare Centres')\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "InClass/ICE2/in-class-2.html#ce2.6-data-wrangling",
    "href": "InClass/ICE2/in-class-2.html#ce2.6-data-wrangling",
    "title": "CE2: Working with Master Plan Planning Subzone Data",
    "section": "CE2.6 Data Wrangling",
    "text": "CE2.6 Data Wrangling\n\npopulation_2023_pivot &lt;- population_2023_pivot %&gt;%\n    # As young boys in Singapore serve 2 years of national service, the earliest age to be considered economically active should be 25.\n    mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n    # By 2026, the retirement age in Singapore will be raised to 64.\n    mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15])) %&gt;%\n    mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n    mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n    / `ECONOMY ACTIVE`) %&gt;%\n    # mutate(): Perform calculation or conversion\n    select(\n        `PA`, `SZ`, `YOUNG`,\n        `ECONOMY ACTIVE`, `AGED`,\n        `TOTAL`, `DEPENDENCY`\n    ) %&gt;% \n    mutate_at(.vars = vars(PA, SZ), .funs = list(toupper)) %&gt;%\n    filter(`ECONOMY ACTIVE` &gt; 0)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.5-geospatial-data-wrangling",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.5-geospatial-data-wrangling",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.5 Geospatial Data Wrangling",
    "text": "H3.5 Geospatial Data Wrangling\nSome geospatial analysis packages require that any input geospatial data be represented with sp’s Spatial* classes. This section introduces a way to convert simple feature data into the Spatial* class.\n\nH3.5.1 Converting sf data frames to Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\nH3.5.2 Converting Spatial* into generic sp format\nspatstat requires the analytical data to be in ppp object form. There is no direct way to convert a Spatial* class into a ppp object. We need to convert it into a Spatial object first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\nOne major difference that can observed between a Spatial class object and generic sp object is the variables, names, min values and max values attributes, which are absent in the latter.\n\n\nH3.5.3 Converting generic sp format into ppp format\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.5.4-handling-duplicates",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.5.4-handling-duplicates",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.5.4 Handling duplicates",
    "text": "H3.5.4 Handling duplicates\nIn spatial point patterns analysis, as is data analytics in general, an issue of significance is the presence of duplicates. These need to be handled, since it is assumed that the points cannot be coincident.\nIn this section, we will:\n\nCheck for duplicated points in our childcare_ppp object;\nCount the number of coincidence points with the multiplicity() function;\nFind the number of locations with more than one point event;\nView the locations of duplicated point events on a map plot;\nPerform jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\n\n\n# Check for duplication\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n# Find multiplicity\nmultiplicity &lt;- multiplicity(childcare_ppp)\nmultiplicity\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n# Print the number of locations with more than 1 point event\nsum(multiplicity &gt; 1)\n\n[1] 0\n\n\nWe can conclude from the above that there are no duplicates in the data.\n\n# Find the locations of duplicate point events\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n# Perform jittering\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\nJittering is one of three ways to deal with missing geospatial data, the others being to make each point “unique” and then attach the duplicate attributes as marks (which would be more complex), or simply remove the data (which might lead to the loss of other important attributes).\n\nH3.5.5 Creating an owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area, such as the national boundary of Singapore. In spatstat, owin is specifically designed to represent this polygonal region and can be defined and output as such:\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\nH3.5.6 Combining point events and owin objects\nFinally, we can extract our childcare centre “events” and combine them with the owin object as such:\n\nchildcare_SG_ppp = childcare_ppp[sg_owin]\nplot(childcare_SG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\nsummary(childcare_SG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.6-first-order-spatial-point-patterns-analysis",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.6-first-order-spatial-point-patterns-analysis",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.6 First Order Spatial Point Patterns Analysis",
    "text": "H3.6 First Order Spatial Point Patterns Analysis\nSpatial point patterns analysis (SPPA) is the study of the spatial arrangements of points in (typically) 2D space. In this section, we will perform first order SPPA using spatstat. In particular, we will:\n\nderive the kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes, and;\nperforming confirmatory spatial point patterns analysis using nearest neighbour statistics.\n\n\nH3.6.1 Kernel Density Estimation\nKernel density estimation (KDE) serves to compute the intensity of a point distribution. It has two general steps: first to compute the point intensity, followed by spatial interpolation using a kernel function (to create distributions like a uniform, triangular, quartic or gaussian distribution). In this exercise, we will mostly use the gaussian kernel.\n\nH3.6.1.1 Computing KDE using automatic bandwidth selection\n\nkde_childcareSG_bw &lt;- density(childcare_SG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nAs we can see, the range of our density values is between 0 and 35*10-4, which is way too small for us. This is because svy21 uses metres by default, which means the density values to be computed will be the number of points per square metre.\nWe will therefore need to rescale our KDE values. Before we move on though, it is good to know that the following code chunk will retrieve us the bandwidth used to compute the KDE layer.\n\nbw &lt;- bw.diggle(childcare_SG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\nH3.6.1.2 Rescaling KDE values\nTo rescale our KDE values, we can convert the unit of measurement into kilometres, and then re-run density() and plot the output map to see the result.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcare_SG_ppp, 1000, \"km\")\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nWe now have a much more readable density map.\n\n\n\nH3.6.2 Working with different automatic bandwidth methods\nOther than bw.diggle(), bw.CvL(), bw.scott() and bw.ppl may be used to determine the bandwidth.\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\nWe can also plot different maps to compare the output of different bandwidth methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\nH3.6.3 Working with different kernel methods\nAs mentioned, there are different kernel methods to give us different distributions. The code chunk below compares the results of three other kernel methods than gaussian, and computes additional kernel density estimations.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.7-fixed-and-adaptive-kde",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.7-fixed-and-adaptive-kde",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.7 Fixed and adaptive KDE",
    "text": "H3.7 Fixed and adaptive KDE\n\nH3.7.1 Computing KDE using fixed bandwidth\nAnother way to compute a KDE layer is by defining a fixed bandwidth. The code chunk below defines a bandwidth (sigma) of 600m (0.6km).\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\nH3.7.2 Computing KDE using adaptive bandwidth\nThe fixed bandwidth method is sensitive to skewed distributions of spatial point patterns (for instance, if a large number of points is clustered in one area, say an urban area, instead of another, like a rural area.) Adaptive bandwidth, using density.adaptive(), is one way to overcome this problem.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nTwo KDE outputs may be compared as follows.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\nH3.7.3 Converting KDE outputs into grid objects\nFor mapping purposes.\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\nH3.7.3.1 Converting gridded output into RasterLayer\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\nH3.7.3.2 Assigning projection system\nNotice that the crs attribute is NA, indicating that no coordinate system has been assigned to the raster. We will fix this by adding the WSY21 (Singapore) CRS to our RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\nH3.7.4 Visualising output in tmap\nFinally, we can display the raster in cartographic quality using tmap.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nWith all the work we have done so far, a quick glance at the maps indicates a higher than usual density of childcare centres in the areas of Woodlands South and Punggol (the yellow patches in the above tmap display).\n\n\nH3.7.5 Comparing Spatial Point Patterns using KDE\nAnd now for the fun part - comparing KDEs between regions. In this section, we will compare the density estimations of childcare centres located in the planning areas of Choa Chu Kang, Jurong West, Punggol and Tampines.\n\nH3.7.5.1 Extracting and plotting study areas\n\n# First, extract the target planning areas\n\npunggol &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntampines &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nchoa_chu_kang &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njurong_west &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n# Then, visualise the areas with a plot\npar(mfrow=c(2,2))\nplot(punggol, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tampines, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(choa_chu_kang, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jurong_west, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\nH3.7.5.2 Creating owin object\n\npg_owin &lt;- as.owin(punggol)\ntm_owin &lt;- as.owin(tampines)\nck_owin &lt;- as.owin(choa_chu_kang)\njw_owin &lt;- as.owin(jurong_west)\n\n\n\nH3.7.5.3 Combining childcare points and the study area\nThe code chunk below completes the following 3 tasks. First, we extract the childcare region for each of our four study areas. Next, we transform the unit of measurement from metres to kilometres. Finally, we can plot the locations of childcare centres within the four study areas.\n\nchildcare_pg_ppp &lt;- childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp &lt;- childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp &lt;- childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp &lt;- childcare_ppp_jit[jw_owin]\n\nchildcare_pg_ppp.km &lt;- rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km &lt;- rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km &lt;- rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km &lt;- rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Childcare centres in Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Childcare centres in Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Childcare centres in Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Childcare centres in Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\nH3.7.5.4 Computing KDE\nFinally, we can compute the KDE for each of the four planning areas with the bw.diggle method.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\nThe KDE displays indicate Punggol as the planning area with the highest density of childcare centres."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.7.4-visualising-output-in-tmap",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.7.4-visualising-output-in-tmap",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.7.4 Visualising output in tmap",
    "text": "H3.7.4 Visualising output in tmap\nFinally, we can display the raster in cartographic quality using tmap.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.7.5-comparing-spatial-point-patterns-using-kde",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.7.5-comparing-spatial-point-patterns-using-kde",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.7.5 Comparing Spatial Point Patterns using KDE",
    "text": "H3.7.5 Comparing Spatial Point Patterns using KDE\nAnd now for the fun part - comparing KDEs between regions. In this section, we will compare the density estimations of childcare centres located in the planning areas of Choa Chu Kang, Jurong West, Punggol and Tampines.\n\nH3.7.5.1 Extracting and plotting study areas"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.8-nearest-neighbour-analysis",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.8-nearest-neighbour-analysis",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.8 Nearest Neighbour Analysis",
    "text": "H3.8 Nearest Neighbour Analysis\nNearest neighbours are the direct distance from points to their nearest neighbours. The nearest neighbour index is expressed as the ratio of the observed mean distance to the expected mean distance. An index of less than 1 indicates the spatial point pattern exhibits clustering, while an index of greater than 1 indicates dispersion or competition. Finally, an index of exactly 1 indicates complete random distribution.\nIn this section, we will perform the Clark-Evans test on the hypothesis that the distribution of childcare services is random.\n\nH3.8.1 Testing spatial point patterns using the Clark-Evans Test\n\nclarkevans.test(childcare_SG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_SG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nWith a p-value of 2.2 * 10-16, we can conclude that the spatial point patterns are not randomly distributed for the entire country, and are instead clustered. We can corroborate this test result with the map visualisations, that indicates that childcare centres are typically located in either the city centre or suburban towns.\nWe can run the test again on each of the sets pertaining to our four planning areas. For now, we will focus on Punggol and Jurong West - the former is a non-mature estate inhabited by more young families, while the latter is a mature estate where residents might have lived in for longer.\n\n\nH3.8.2 Clark-Evans Test: Punggol\n\nclarkevans.test(childcare_pg_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.91633, p-value = 0.2112\nalternative hypothesis: two-sided\n\n\n\n\nH3.8.3 Clark-Evans Test: Jurong West\n\nclarkevans.test(childcare_jw_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_jw_ppp\nR = 0.9087, p-value = 0.1013\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.9-second-order-spatial-points-patterns-analysis",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.9-second-order-spatial-points-patterns-analysis",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.9 Second Order Spatial Points Patterns Analysis",
    "text": "H3.9 Second Order Spatial Points Patterns Analysis\nWhile first order SPPA measures how observations vary due to changes in the underlying property, second order SPPA deals with variations in observations due to the way they interact with one another. The methods used for second order SPPA include the F-, G-, K- and L-functions.\nIn this section, we will explore the F-, G- K- and L-functions by applying them on the childcare centre data for the planning areas of Choa Chu Kang in Western Singapore, and Tampines in the East."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.10-f-function",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.10-f-function",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.10 F-Function",
    "text": "H3.10 F-Function\nThe F-function estimates the empty space function \\(F(r)\\) from a point pattern in a window of arbitrary shape. It can be computed using Fest() of the spatstat package.\nFollowing that, a Monte Carlo simulation test can be performed using envelope(). We will perform both operations on the segments of the data representing\n\nH3.10.1 Computing F-function estimations\n\nH3.10.1.1 Choa Chu Kang\n\nF_function_Choa_Chu_Kang &lt;- Fest(childcare_ck_ppp)\nplot(F_function_Choa_Chu_Kang)\n\n\n\n\n\n\n\n\n\n\nH3.10.1.2 Tampines\n\nF_function_Tampines &lt;- Fest(childcare_tm_ppp, correction=\"best\")\nplot(F_function_Tampines)\n\n\n\n\n\n\n\n\n\n\n\nH3.10.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we can conduct a Monte Carlo (hypothesis) test with envelope(). The hypothesis and test are as follows:\nH0 = The distribution of childcare services at Choa Chu Kang/Tampines are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang/Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nH3.10.2.1 Choa Chu Kang\n\nF_CCK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CCK.csr)\n\n\n\n\n\n\n\n\n\n\nH3.10.2.2 Tampines\n\nF_TM.csr &lt;- envelope(childcare_tm_ppp, Fest, correction=\"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_TM.csr)\n\n\n\n\n\n\n\n\nThe F-function for the Choa Chu Kang set is within the envelope, and that for the Tampines set is below the envelope. This indicates that indicating that the childcare centres in Choa Chu Kang exhibit complete spatial randomness (CSR), while the centres in Tampines are clustered."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.10.1-computing-f-function-estimation-for-choa-chu-kang-planning-area",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.10.1-computing-f-function-estimation-for-choa-chu-kang-planning-area",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.10.1 Computing F-function estimation for Choa Chu Kang planning area",
    "text": "H3.10.1 Computing F-function estimation for Choa Chu Kang planning area\n\nF_CCK = Fest(childcare_ck_ppp)\nplot(F_CCK)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.10.2-performing-complete-spatial-randomness-test",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.10.2-performing-complete-spatial-randomness-test",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.10.2 Performing Complete Spatial Randomness Test",
    "text": "H3.10.2 Performing Complete Spatial Randomness Test"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.11-g-function",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.11-g-function",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.11 G-Function",
    "text": "H3.11 G-Function\nThe G-function measures the distribution of distances from an arbitrary event to its nearest event.\nOnce again, a function from the spatstat package will be used, this time the Gest() function. Following that, we will perform another Monte Carlo simulation test with envelope().\n\nH3.11.1 Computing G-function estimations\n\nH3.11.1.1 Choa Chu Kang\n\nG_CK &lt;- Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nH3.11.1.2 Tampines\n\nG_tm &lt;- Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n\nH3.11.2 Performing Complete Spatial Randomness Test\nAs a reminder:\nH0 = The distribution of childcare services at Choa Chu Kang/Tampines are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang/Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nH3.11.2.1 Choa Chu Kang\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\nH3.11.2.2 Tampines\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\nUnlike the function for Choa Chu Kang, which lies entirely within the envelopes, a small portion of the Tampines function falls above the envelopes. Once again, this indicates that the childcare centres of Choa Chu Kang exhibit CSR, while those in Tampines are clustered."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.12-k-function",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.12-k-function",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.12 K-Function",
    "text": "H3.12 K-Function\nThe K-function measures the number of events found up to a given distance of any particular event. For this exercise, the spatstat function to be used is the the Kest() function, and another Monte Carlo simulation test will be performed with envelope().\n\nH3.12.1 Computing K-function estimations\n\nH3.12.1.1 Choa Chu Kang\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nH3.12.1.2 Tampines\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nH3.12.2 Performing Complete Spatial Randomness Test\nAs a reminder:\nH0 = The distribution of childcare services at Choa Chu Kang/Tampines are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang/Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nH3.12.2.1 Choa Chu Kang\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\nH3.12.2.2 Tampines\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\nThe Choa Chu Kang K-function lies entirely inside the envelope, while much of that for Tampines lies above it. Once again, this shows that the Choa Chu Kang childcare centres are randomly distributed (CSR). The K-function indicates that the childcare centres in Tampines exhibit a significant regular pattern."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.13-l-function",
    "href": "HandsOn/Hands-on_Ex03/hands-on-3.html#h3.13-l-function",
    "title": "H3: Spatial Point Patterns Analysis",
    "section": "H3.13 L-Function",
    "text": "H3.13 L-Function\nThe L-function is a normalisation of the K-function so as to obtain a benchmark of zero.\nFor this exercise, the spatstat function to be used is the the Lest() function, and another Monte Carlo simulation test will be performed with envelope().\n\nH3.13.1 Computing L-function estimations\n\nH3.13.1.1 Choa Chu Kang\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\nH3.13.1.2 Tampines\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\nH3.13.2 Performing Complete Spatial Randomness Test\n\nH3.13.2.1 Choa Chu Kang\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\nH3.13.2.2 Tampines\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis (Incomplete)",
    "section": "",
    "text": "Network Constrained Spatial Point Patterns Analysis (NetSPPA) is a collection of spatial point patterns analysis (SPPA) methods special developed for analysing spatial point event occurs on or alongside a network. Examples of networks are road, train and river networks, while examples of spatial point events include locations of events like crime, or facilities like schools and parks.\nThis exercise will be on the spNetwork package, which serves to derive network kernel density estimation (NKDE), as well as to perform network G- and K-function analysis. Continuing on our theme of childcare centres, we will analyise the spatial distribution of childcare centres in the relatively young, northeastern planning area of Punggol. Two geospatial datasets in ESRI shapefile format will be used, namely:\n\nPunggol_St, a line featureset storing information on Punggol’s road network, and;\nPunggol_CC, a point featureset storing the locations of Punggol’s childcare centres."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.1-overview",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.1-overview",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.1-overview-and-data",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.1-overview-and-data",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis (Incomplete)",
    "section": "",
    "text": "Network Constrained Spatial Point Patterns Analysis (NetSPPA) is a collection of spatial point patterns analysis (SPPA) methods special developed for analysing spatial point event occurs on or alongside a network. Examples of networks are road, train and river networks, while examples of spatial point events include locations of events like crime, or facilities like schools and parks.\nThis exercise will be on the spNetwork package, which serves to derive network kernel density estimation (NKDE), as well as to perform network G- and K-function analysis. Continuing on our theme of childcare centres, we will analyise the spatial distribution of childcare centres in the relatively young, northeastern planning area of Punggol. Two geospatial datasets in ESRI shapefile format will be used, namely:\n\nPunggol_St, a line featureset storing information on Punggol’s road network, and;\nPunggol_CC, a point featureset storing the locations of Punggol’s childcare centres."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.2-installing-and-launching-r-packages",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.2-installing-and-launching-r-packages",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis (Incomplete)",
    "section": "H4.2 Installing and launching R packages",
    "text": "H4.2 Installing and launching R packages\nThe R packages to be used today are:\n\nspNetwork, for performing SPPA procedures like KDE and K-functions on the network. It can also be used to build spatial matrices to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf\ntmap, particularly the leaflet API, which helps us plot cartographic-quality static point pattern maps or interactive maps.\n\n\n# pacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.3-data-import-preparation-and-visualisation",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.3-data-import-preparation-and-visualisation",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis (Incomplete)",
    "section": "H4.3 Data Import, Preparation and Visualisation",
    "text": "H4.3 Data Import, Preparation and Visualisation\nAs always, the first step is to import our geospatial datasets into RStudio as sf dataframes.\n\n# network &lt;- st_read(dsn=\".../data/geospatial\", \n#                    layer=\"Punggol_St\")\n# network\n# childcare &lt;- st_read(dsn=\".../data/geospatial\",\n#                      layer=\"Punggol_CC\")\n# childcare\n# plot(st_geometry(network))\n# plot(childcare, add=T, col='blue', pch=19)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.4-network-kde-analysis",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.4-network-kde-analysis",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis (Incomplete)",
    "section": "H4.4 Network KDE Analysis",
    "text": "H4.4 Network KDE Analysis\nNetwork KDE (NKDE) analysis can be performed by using appropriate functions from the spNetwork package.\n\nH4.4.1 Preparing lixel objects\nBefore finding the NKDE, we need to first cut our SpatialLines objects into lixels with a specified minimal distance. We can do this by calling lixelize_lines() as shown. In the code chunk below:\n\nThe length of a lixel, taken in with the lx_length parameter, is set to 700 metres, and;\nThe minimum length of a lixel, as defined in the mindist parameter, is 375 metres.\n\n\n# lixels &lt;- lixelize_lines(network, \n#                          700, \n#                          mindist = 375)\n\nAfter cutting, the length of the final lixel, if shorter than the minimum distance, is added to the previous lixel. If mindist is not defined (NULL), then it is maxdist / 10. Segments that are already shorter than the minimum distance are also not modified.\n\n\nH4.4.2 Generating line centre points\nNext, the code chunk below will generate a SpatialPointsDataFrame (i.e. samples) with line centre points. These points are located at the centre of the line based on its length.\n\n# samples &lt;- lines_center(lixels)\n\n\n\nH4.4.3 Performing NKDE\nWe are now ready to compute the NKDE by using the following code chunk.\n\n# densities &lt;- nkde(network, \n#                   events = childcare,\n#                   w = rep(1, nrow(childcare)),\n#                   samples = samples,\n#                   kernel_name = \"quartic\",\n#                   bw = 300, \n#                   div= \"bw\", \n#                   method = \"simple\", \n#                   digits = 1, \n#                   tol = 1,\n#                   grid_shape = c(1,1), \n#                   max_depth = 8,\n#                   agg = 5, \n#                   sparse = TRUE,\n#                   verbose = FALSE)\n\nSome interesting elements to note from the above code chunk include:\n\nThe quartic kernel is to be used for this NKDE exercise, and is passed into the kernel_name argument.\nThe simple keyword is passed into the method argument, which indicates it is to be used to find the NKDE.\n\nThree popular methods are currently supported by spNetwork - simple, discontinuous and continuous. simple uses network distances between events and sampling points, and the density is calculated over a linear unit (like metres) instead of an areal unit (like square metres). discontinuous “divides” the mass density of an event at intersections of lixels, while continuous divides the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\nH4.4.3.1 Visualising NKDE\nWe are now ready to visualise our computed NKDE values, but not before doing some preparatory work beforehand.\nFirst, we need to insert the computed density values (densities) into the density fields of our samples and lixels objects.\n\n# samples$density &lt;- densities\n# lixels$density &lt;- densities\n\nNext, we have to rescale our density values by kilometres, up from the current metres. As we’ve seen in a previous hands-on exercise, leaving the projection system in metres (the SVY21 default) leads to extremely small computed density values.\n\n# samples$density &lt;- samples$density * 1000\n# lixels$density &lt;- lixels$density * 1000\n\nFinally, we can draw our interactive and high-quality map visualisation.\n\n# tmap_mode('view')\n# tm_shape(lixels)+\n#   tm_lines(col=\"density\")+\n# tm_shape(childcare)+\n#   tm_dots()\n# tmap_mode('plot')\n\nThe interactive map above effectively distinguishes road segments with a relatively higher density of childcare centres (darker color) than those with a relatively lower density of childcare centres (lighter color)."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex05/hands-on-5.html",
    "href": "HandsOn/Hands-on_Ex05/hands-on-5.html",
    "title": "H5: Spatial Weights and Appliations (Incomplete)",
    "section": "",
    "text": "This exercise is on computing spatial weights with R. For this exercise, the following datasets, set in Hunan Province, China, will be used:\n\nThe Hunan country boundary layer, in ESRI shapefile format, and;\nHunan_2012.csv, an aspatial dataset containing selected local development indicators for the area in 2012.\n\nIn addition to the usual sf, readr and dplyr packages, spatial weights and spatially lagged variables will be computed using appropriate spdep functions.\n\n\nAfter loading our packages, our data will be imported into the R environment.\n\n# pacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n# hunan &lt;- st_read(dsn = \"../data/geospatial\",\n#                  layer = \"Hunan\")\n# dev_2012 &lt;- read_csv(\"../data/aspatial/Hunan_2012.csv\")\n\n\n\n\nWe can now perform a left join of the Hunan 2012 development dataset on the map of Hunan province:\n\n# hunan &lt;- left_join(hunan,dev_2012)%&gt;%\n#   select(1:4, 7, 15)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.1-overview-study-area-and-data",
    "href": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.1-overview-study-area-and-data",
    "title": "H5: Spatial Weights and Appliations (Incomplete)",
    "section": "",
    "text": "This exercise is on computing spatial weights with R. For this exercise, the following datasets, set in Hunan Province, China, will be used:\n\nThe Hunan country boundary layer, in ESRI shapefile format, and;\nHunan_2012.csv, an aspatial dataset containing selected local development indicators for the area in 2012.\n\nIn addition to the usual sf, readr and dplyr packages, spatial weights and spatially lagged variables will be computed using appropriate spdep functions.\n\n\nAfter loading our packages, our data will be imported into the R environment.\n\n# pacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n# hunan &lt;- st_read(dsn = \"../data/geospatial\",\n#                  layer = \"Hunan\")\n# dev_2012 &lt;- read_csv(\"../data/aspatial/Hunan_2012.csv\")\n\n\n\n\nWe can now perform a left join of the Hunan 2012 development dataset on the map of Hunan province:\n\n# hunan &lt;- left_join(hunan,dev_2012)%&gt;%\n#   select(1:4, 7, 15)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.5-network-constrained-g--and-k-function-analysis",
    "href": "HandsOn/Hands-on_Ex04/hands-on-4.html#h4.5-network-constrained-g--and-k-function-analysis",
    "title": "H4: Network Constrained Spatial Point Patterns Analysis (Incomplete)",
    "section": "H4.5 Network-Constrained G- and K-Function Analysis",
    "text": "H4.5 Network-Constrained G- and K-Function Analysis\nThe last step is to perform a complete spatial randomness (CSR) test by running our data through a K-function. The function to be used is kfunctions(), once again from the spNetwork package.\nToday’s null hypothesis is defined as:\nH0: The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol.\nIn other words, our childcare centres are randomly and independently distributed over the street network. If this null hypothesis is rejected, we may infer that the childcare centres in Punggol are spatially dependent on each other; as a result, they may form non-random patterns.\n\n# kfun_childcare &lt;- kfunctions(network, \n#                              childcare,\n#                              start = 0, \n#                              end = 1000, \n#                              step = 50, \n#                              width = 50, \n#                              nsim = 50, \n#                              resolution = 50,\n#                              verbose = FALSE, \n#                              conf_int = 0.05)\n\nThe ten arguments required by kfunctions() are:\n\nlines: A SpatialLinesDataFrame with the sampling points.\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: A double, the start value for evaluating the K- and G- functions.\nend: A double, the last value for evaluating the K- and G- functions.\nstep: A double, the jump between two evaluations of the K- and G- function.\nwidth: The width of each donut for the g-function.\nnsim: An integer indicating the number of Monte Carlo simulations required. In the above example, 50 simulations were performed, but it is usually preferred to have more simulations.\nresolution: When simulating random points on the network, selecting a resolution will reduce greatly the calculation time. When the resolution is NULL, the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points are selected vertices on the new network.\nconf_int: A double indicating the width confidence interval (default = 0.05).\n\nkfunctions() outputs:\n\nplotkA, a ggplot2 object representing the values of the K-function;\nplotgA, a ggplot2 object representing the values of the G-function;\nvaluesA, a DataFrame with the values used to build the plots.\n\nFinally, we can visualise the ggplot2 object of our K-function as follows.\n\n# kfun_childcare$plotk\n\nSince the observed values for the distance interval of 250-400m are below the envelop, we can infer that the childcare centres in Punggol resemble a regular pattern for that distance."
  },
  {
    "objectID": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.2-visualising-our-data",
    "href": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.2-visualising-our-data",
    "title": "H5: Spatial Weights and Appliations (Incomplete)",
    "section": "H5.2 Visualising our Data",
    "text": "H5.2 Visualising our Data\nUsing qtm() and other tmap packages, we can now prepare a basemap and choropleth map showing the distribution of GDP per capita by region.\n\n# basemap &lt;- tm_shape(hunan) +\n#   tm_polygons() +\n#   tm_text(\"NAME_3\", size=0.5)\n\n# gdppc &lt;- qtm(hunan, \"GDPPC\")\n# tmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.3-computing-contiguity-spatial-weights",
    "href": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.3-computing-contiguity-spatial-weights",
    "title": "H5: Spatial Weights and Appliations (Incomplete)",
    "section": "H5.3 Computing Contiguity Spatial Weights",
    "text": "H5.3 Computing Contiguity Spatial Weights\nThe poly2nb() function of the spdep package may be used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with continuous boundaries.\n\nH5.3.1 Creating QUEEN contiguity-based neighbours\n\n# wm_q &lt;- poly2nb(hunan, queen=TRUE)\n# summary(wm_q)\n\nFor each polygon in our polygon object, wm_q lists all neighbouring polygons. The following code chunk reveals the neighbours for the first polygon in the object. It is good to be reminded here that R is not a zero-index index, so all list indices start from 1.\n\n# wm_q[[1]]\n\nWe can also retrieve the county name with Polygon ID=1 as follows:\n\n# hunan$County[1]\n\nOr the county names of the five counties bordering county ID 1:\n\n# hunan$NAME_3[c(2,3,4,57,85)]\n\nFinally, we can retrieve the GDP per capita of each of the five counties bordering county ID 1:\n\n# nb1 &lt;- wm_q[[1]]\n# nb1 &lt;- hunan$GDPPC[nb1]\n# nb1\n\nThe complete weight matrix may be displayed using str(). It’s a long one.\n\n# str(wm_q)\n\n\n\nH5.3.2 Creating ROOK contiguity-based neighbours\nAside from the QUEEN contiguity weight matrix, we can also create ROOK contiguity based neighbours by setting the queen parameter to FALSE. The summary report below shows there are 88 area units in Hunan Province, with the most connected area unit having 10 neighbours.\n\n# wm_r &lt;- poly2nb(hunan, queen=FALSE)\n# summary(wm_r)\n\n\n\nH5.3.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids, which we can calculate these in the sf package.\n\nH5.3.3.1 Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\n# longitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\n# latitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\n# coords &lt;- cbind(longitude, latitude)\n\nWe can check the first few observations to see if things are formatted correctly.\n\n# head(coords)\n\n\n\nH5.3.3.2 Plotting Queen contiguity based neighbours map\n\n# plot(hunan$geometry, border=\"lightgrey\")\n# plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\nH5.3.3.3 Plotting Rookc contiguity based neighbours map\n\n# plot(hunan$geometry, border=\"lightgrey\")\n# plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\nH5.4 Computing distance-based neighbours\nDistance-based weight matrices may be derived using dnearneigh(). This function identifies neighbours of region points by Euclidean distance with a lower bound of d1 and upper bound of d2, controlled by the bounds parameter. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix, and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nH5.4.1 Determining the cutoff distance\nTo determine the upper limit for the distance band, we can follow the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other using knearneigh();\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number IDs using knn2nb()\nReturn the length of neighbour relationship edges using nbdists(), which returns in the units of the coordinates if one is projected, and in kilometres otherwise.\nRemove the list structure of the returned object using unlist().\n\n\n# coords &lt;- coordinates(hunan)\n# k1 &lt;- knn2nb(knearneigh(coords))\n# k1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\n# summary(k1dists)\n\n\n\nH5.4.2 Computing fixed distance weight matrix using dnearneigh()\n\n# wm_d62 &lt;- dnearneigh(coords, 0, 62, longlat=TRUE)\n# wm_d62\n\nNext, we use str() to display the content of our matrix.\n\n# str(wm_d62)\n\nWe can also display the weight matrix in a table form by combining table() and card(), from spdep.\n\n# table(human$County, card(wm_d62))\n\n\nH5.4.2.1 Plotting fixed distance weight matrix\nA weight matrix can now be plotted as below:\n\n# plot(hunan$geometry, border=\"lightgrey\")\n# plot(wm_d62, coords, add=TRUE)\n# plot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\nThe red lines show links of first nearest neighbours, while the black lines show the links of neighbours within the cutoff distance of 62km.\nAlternatively, we can plot both of these next to each other as below:\n\n# par(mfrow=c(1,2))\n# plot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\n# plot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n# plot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\n# plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\nH5.4.3 Computing distance matrix\nA key characteristic involving fixed distance weight matrices is that more densly-populated areas (usually urban areas) tend to have more neighbours than their less densly-populated counterparts. Yet, having many neighbours smoothes the neighbour relationship across more neighbours. It is possible to control the number of neighbours directly using K-nearest neighbours, by either accepting asymmetric neighbours or imposing symmetry as shown below.\n\n# knn6 &lt;- knn2nb(knearneigh(coords, k=6))\n# knn6\n# str(knn6)\n\n\n\nH5.4.3.1 Plotting distance-based neighbours\n\n# plot(hunan$geometry, border=\"lightgrey\")\n# plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\nH5.5 Weights based on IDW\nThis section serves to derive a spatial weight matrix based on the inversed distance method.\nFirst, we compute the distance between areas using nbdists().\n\n# dist &lt;- nbdists(wm_q, coords, longlat = TRUE)\n# ids &lt;- lapply(dist, function(x) 1/(x))\n# ids\n\n\n\nH5.6 Row-standardised Weights Matrix\nNext, we need to assign weights to each neighbouring polygon. In our case, each neighbouring polygon will be assigned equal weight (style=\"W\").\n\n# rswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\n# rswm_q\n# rswm_ids$weights[1]\n# summary(unlist(rswm_ids$weights))"
  },
  {
    "objectID": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.7-applications-of-spatial-weight-matrices",
    "href": "HandsOn/Hands-on_Ex05/hands-on-5.html#h5.7-applications-of-spatial-weight-matrices",
    "title": "H5: Spatial Weights and Appliations (Incomplete)",
    "section": "H5.7 Applications of Spatial Weight Matrices",
    "text": "H5.7 Applications of Spatial Weight Matrices\nSpatial weight matrices are used to create spatial lagged variables. In this section, four of them will be created: first with row-standardised weights, second as a sum of neighbouring values, third a spatial window average, and fourth a spatial window sum.\n\nH5.7.1 Row-standardised weights\nFirst, the average neighbour GDP per capita value for each polygon is calculated.\n\n# GDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\n# GDPPC.lag\n\nIn the previous section, we retrieved the GDP per capita of the five neighbours with this code chunk:\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\nWe can then append the spatially lag GDP per capita values onto the hunan dataset by using the code chunk below, and print out the average neighbouring income values for each county. Following that, we can plot both GDP per capita and spatial lag GDP per capita for comparison.\n\n# lag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\n# lag.res &lt;- as.data.frame(lag.list)\n# colnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\n# hunan &lt;- left_join(hunan,lag.res)\n# head(hunan)\n# gdppc &lt;- qtm(hunan, \"GDPPC\")\n# lag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\n# tmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\nH5.7.2 Spatial lag as a sum of neighbouring values\nWe can also calculate spatial lag as a sum of neighbouring values by assigning binary weights. This requires us to go back to the neighbours list, apply a function to assign binary weights, then explicitly assign the weights with the glist= parameter in the nb2listw() function.\nWe start by applying a function that will assign a value of 1 per neighbour. This is done with lapply(), which was used before to manipulate neighbour structure. The lapply() a function across each value in the neighbours structure.\n\n# b_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\n# b_weights2 &lt;- nb2listw(wm_q,\n#                        glist = b_weights,\n#                        style = \"B\")\n# b_weights2\n\nWith the proper weights assigned, we can use lag.listw() to compute a lag variable from our weight and GDP per capita. We can then examine the result with the code chunk below.\n\n# lag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\n# lag.res &lt;- as.data.frame(lag_sum)\n# colnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n# lag_sum\n\nNext, let’s left join the GDPPC field of lag_sum into the hunan dataframe. After that, we can plot both the original dataset and the spatial lag sum dataset for comparison.\n\n# gdppc &lt;- qtm(hunan, \"GDPPC\")\n# lag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\n# tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\nH5.7.3 Spatial window average\nThe spatial window average uses row-standardised weights and includes the diagonal element. To do this in R, we need to go back to the neighbours structure and add the diagonal element before assigning weights with include.self(wm_q) before assigning weights.\n\n# wm_qs &lt;- include.self(wm_q)\n# wm_qs[[1]]\n\nNotice that [1] now has 6 neighbours instead of 5. We can now proceed to obtain and assign weight values to our\n\n# wm_qs &lt;- nb2listw(wm_qs)\n# wm_qs\n# lag_w_avg_gpdpc &lt;- lag.listw(wm_qs,\n#     glist = b_weights,\n#     style = \"B\"\n# )\n# lag_w_avg_gpdpc\n\nThe final steps are to:\n\nConvert the lag variable listw object into a dataframe;\nLeft joining our lag window back to the hunan dataframe;\nCompare the spatial lag weights and spatial window average by plotting the lag_gdppc and w_ave_dgppc maps side by side.\n\n\n# lag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\n# lag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\n# colnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n# hunan &lt;- left_join(hunan, lag_wm_qs.res)\n# w_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\n# tmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\nTo compare the values of lag GDPPC and Spatial window average, we can use kable() from the Knitr package to prepare a table.\n\n# hunan %&gt;%\n#   select(\"County\", \n#          \"lag GDPPC\", \n#          \"lag_window_avg GDPPC\") %&gt;%\n#   kable()\n\n\n\nH5.7.4 Spatial Window Sum\nUnlike the spatial window average, the spatial window sum does not use row-standardised weights. The first two steps to creating our spatial window sum are the same as before - add the diagonal element from the neighbour list and assign binary weights. The lag variable is then computed with lag.listw(), then converted into a data frame and left joined back to the hunan data frame.\n\n# w_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\n# w_sum_gdppc\n# w_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\n# colnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n# hunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nFinally, we can compare the spatial lag weights and spatial window average by plotting the lag_sum_gdppc and w_sum_gdppc maps side by side. We can also construct a kable() table to compare the results in tabular form.\n\n# w_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\n# tmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n# hunan %&gt;%\n#   select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n#   kable()"
  },
  {
    "objectID": "index.html#featured-exercises",
    "href": "index.html#featured-exercises",
    "title": "IS415: Geospatial Analytics and Applications",
    "section": "Featured Exercises",
    "text": "Featured Exercises\nHands-on Exercise 1: Geospatial Data Wrangling with R\nHands-on Exercise 2: Thematic Mapping and GeoVisualisation with R\nHands-on Exercise 3: Spatial Point Patterns Analysis"
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html",
    "href": "TakeHome/TakeHome1/take-home-1.html",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict every year. One of these is the Myanmar Civil War, a significant escalation of the long-running Myanmar Conflict in response to the 2021 coup d’etat.\nGeospatial analtyics holds the potential to address complex problems facing society, such as this one. This study serves to discover the sptial and spatio-temporal distribution (spread) of the armed conflict in Myanmar by applying spatial point pattern analysis (SPPA) methods."
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.1-setting-the-scene",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.1-setting-the-scene",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict every year. One of these is the Myanmar Civil War, a significant escalation of the long-running Myanmar Conflict in response to the 2021 coup d’etat.\nGeospatial analtyics holds the potential to address complex problems facing society, such as this one. This study serves to discover the sptial and spatio-temporal distribution (spread) of the armed conflict in Myanmar by applying spatial point pattern analysis (SPPA) methods."
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.2-the-data",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.2-the-data",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.2 The Data",
    "text": "TH1.2 The Data\nArmed conflict data in Myanmar between 2010 and 2024 was downloaded from the Armed Conflict Location & Event Database (ACLED), an independent, impartial, international non-profit organization collecting data on violent conflicts and protests in all countries and territories in the world. We will be superimposing these locations with the geogrpahical boundary and subdivisions of the country, from the Myanmar Information Management Unit (MIMU).\nWe are interested in conflict events from 2019 onwards - starting from a year before the COVID-19 pandemic and 2 years before the 2021 coup - cumulating into the civil war of today."
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.3-using-appropriate-function-of-sf-and-tidyverse-packages-import-and-transform-the-downloaded-armed-conflict-data-and-administrative-boundary-data-into-sf-tibble-data.frames",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.3-using-appropriate-function-of-sf-and-tidyverse-packages-import-and-transform-the-downloaded-armed-conflict-data-and-administrative-boundary-data-into-sf-tibble-data.frames",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.3 Using appropriate function of sf and tidyverse packages, import and transform the downloaded armed conflict data and administrative boundary data into sf tibble data.frames",
    "text": "TH1.3 Using appropriate function of sf and tidyverse packages, import and transform the downloaded armed conflict data and administrative boundary data into sf tibble data.frames\n\nTH1.3.1 Loading R packages and importing data\nThe R packages we will use today are:\n\nsf\ntmap\nspatstat\nraster\nmaptools\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nmmr_polbnda &lt;- st_read(dsn=\"data/mmr_polbnda_adm1_250k_mimu_1\", layer=\"mmr_polbnda_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm1_250k_mimu_1' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/TakeHome/TakeHome1/data/mmr_polbnda_adm1_250k_mimu_1' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nmmr_polbnda\n\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE           ST_RG          ST_MMR PCode_V\n1         1  Ayeyarwady   MMR017          Region  ဧရာဝတီတိုင်းဒေသကြီး     9.4\n2         2        Bago   MMR111          Region    ပဲခူးတိုင်းဒေသကြီး     9.4\n3         4        Chin   MMR004           State       ချင်းပြည်နယ်     9.4\n4         5      Kachin   MMR001           State       ကချင်ပြည်နယ်     9.4\n5         6       Kayah   MMR002           State       ကယားပြည်နယ်     9.4\n6         7       Kayin   MMR003           State        ကရင်ပြည်နယ်     9.4\n7         8      Magway   MMR009          Region   မကွေးတိုင်းဒေသကြီး     9.4\n8         9    Mandalay   MMR010          Region မန္တလေးတိုင်းဒေသကြီး     9.4\n9        10         Mon   MMR011           State         မွန်ပြည်နယ်     9.4\n10       11 Nay Pyi Taw   MMR018 Union Territory        နေပြည်တော်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.20798 15...\n2  MULTIPOLYGON (((96.17964 19...\n3  MULTIPOLYGON (((93.36931 24...\n4  MULTIPOLYGON (((97.59674 28...\n5  MULTIPOLYGON (((97.1759 19....\n6  MULTIPOLYGON (((97.81508 16...\n7  MULTIPOLYGON (((94.11699 22...\n8  MULTIPOLYGON (((96.14023 23...\n9  MULTIPOLYGON (((97.73689 15...\n10 MULTIPOLYGON (((96.32013 20...\n\nacled_mya &lt;- read_csv(\"data/ACLED_Myanmar.csv\")\n\nRows: 55574 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nacled_mya\n\n# A tibble: 55,574 × 31\n   event_id_cnty event_date        year time_precision disorder_type  event_type\n   &lt;chr&gt;         &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;     \n 1 MMR56099      31 December 2023  2023              1 Political vio… Explosion…\n 2 MMR56222      31 December 2023  2023              1 Political vio… Explosion…\n 3 MMR56370      31 December 2023  2023              1 Political vio… Battles   \n 4 MMR56376      31 December 2023  2023              1 Demonstrations Protests  \n 5 MMR56380      31 December 2023  2023              1 Strategic dev… Strategic…\n 6 MMR56869      31 December 2023  2023              1 Strategic dev… Strategic…\n 7 MMR56871      31 December 2023  2023              1 Political vio… Battles   \n 8 MMR56873      31 December 2023  2023              1 Political vio… Explosion…\n 9 MMR56874      31 December 2023  2023              1 Political vio… Battles   \n10 MMR56876      31 December 2023  2023              1 Political vio… Violence …\n# ℹ 55,564 more rows\n# ℹ 25 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, geo_precision &lt;dbl&gt;, source &lt;chr&gt;,\n#   source_scale &lt;chr&gt;, notes &lt;chr&gt;, fatalities &lt;dbl&gt;, tags &lt;chr&gt;, …"
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.3-importing-and-transforming-armed-conflict-data-and-administrative-boundary-data-into-sf-tibble-data.frames",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.3-importing-and-transforming-armed-conflict-data-and-administrative-boundary-data-into-sf-tibble-data.frames",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.3 Importing and transforming armed conflict data and administrative boundary data into sf tibble data.frames",
    "text": "TH1.3 Importing and transforming armed conflict data and administrative boundary data into sf tibble data.frames\n\nTH1.3.1 Loading R packages and aspatial data\nThe R packages we will use today are:\n\nsf\ntmap\nspatstat\nraster\nmaptools\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nacled_mya &lt;- read_csv(\"data/ACLED_Myanmar.csv\")\n\nRows: 55574 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(acled_mya)\n\n# A tibble: 6 × 31\n  event_id_cnty event_date        year time_precision disorder_type   event_type\n  &lt;chr&gt;         &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;     \n1 MMR56099      31 December 2023  2023              1 Political viol… Explosion…\n2 MMR56222      31 December 2023  2023              1 Political viol… Explosion…\n3 MMR56370      31 December 2023  2023              1 Political viol… Battles   \n4 MMR56376      31 December 2023  2023              1 Demonstrations  Protests  \n5 MMR56380      31 December 2023  2023              1 Strategic deve… Strategic…\n6 MMR56869      31 December 2023  2023              1 Strategic deve… Strategic…\n# ℹ 25 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, geo_precision &lt;dbl&gt;, source &lt;chr&gt;,\n#   source_scale &lt;chr&gt;, notes &lt;chr&gt;, fatalities &lt;dbl&gt;, tags &lt;chr&gt;,\n#   timestamp &lt;dbl&gt;\n\n\n\n\nTH1.3.2 Loading and plotting geospatial data\nThree representations of Myanmar’s geography exist on - Admin1 subdivides the country into its states and regions only, while Admin2 subdivides the country by its smaller districts, and Admin3 its townships. Further, the ACLED labels each incident with all 3 representations. For simplicity and ease of understanding, we shall use the Admin1 representation.\n\nmmr_admin1 &lt;- st_read(dsn=\"data/mmr_polbnda_adm1_250k_mimu_1\", layer=\"mmr_polbnda_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm1_250k_mimu_1' from data source \n  `/Users/kendricktty/Gits/SMU_CS/is415-site/TakeHome/TakeHome1/data/mmr_polbnda_adm1_250k_mimu_1' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nmmr_admin1\n\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE           ST_RG          ST_MMR PCode_V\n1         1  Ayeyarwady   MMR017          Region  ဧရာဝတီတိုင်းဒေသကြီး     9.4\n2         2        Bago   MMR111          Region    ပဲခူးတိုင်းဒေသကြီး     9.4\n3         4        Chin   MMR004           State       ချင်းပြည်နယ်     9.4\n4         5      Kachin   MMR001           State       ကချင်ပြည်နယ်     9.4\n5         6       Kayah   MMR002           State       ကယားပြည်နယ်     9.4\n6         7       Kayin   MMR003           State        ကရင်ပြည်နယ်     9.4\n7         8      Magway   MMR009          Region   မကွေးတိုင်းဒေသကြီး     9.4\n8         9    Mandalay   MMR010          Region မန္တလေးတိုင်းဒေသကြီး     9.4\n9        10         Mon   MMR011           State         မွန်ပြည်နယ်     9.4\n10       11 Nay Pyi Taw   MMR018 Union Territory        နေပြည်တော်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.20798 15...\n2  MULTIPOLYGON (((96.17964 19...\n3  MULTIPOLYGON (((93.36931 24...\n4  MULTIPOLYGON (((97.59674 28...\n5  MULTIPOLYGON (((97.1759 19....\n6  MULTIPOLYGON (((97.81508 16...\n7  MULTIPOLYGON (((94.11699 22...\n8  MULTIPOLYGON (((96.14023 23...\n9  MULTIPOLYGON (((97.73689 15...\n10 MULTIPOLYGON (((96.32013 20...\n\nqtm(mmr_admin1)\n\n\n\n\n\n\n\n\n\n\nTH1.3.3 Creating sf data frame from aspatial data\nThe ACLED data contains coordinates, making it useful for plotting on our map as points. We can therefore use it to create an sf data frame which we can use to plot our points on a map. The EPSG format of the import coordinates should be 4326, corresponding to the WGS84 Geographic Coordinate System.\n\nacled_mya_sf &lt;- st_as_sf(acled_mya, coords = c(\"longitude\", \"latitude\"), crs=4326) \n\nThe EPSG area code for Myanmar is 4239. Before we work with our datasets, we will need to transform the coordinate system to use it.\n\nacled_mya_sf &lt;- acled_mya_sf %&gt;% st_transform(crs=4239)\nmmr_admin1 &lt;- mmr_admin1 %&gt;% st_transform(crs=4239)\ntm_shape(mmr_admin1) + tm_polygons() + tm_shape(acled_mya_sf) + tm_dots(size=0.05)\n\n\n\n\n\n\n\n\nAdditionally, since the data is timestamped, we are able to plot and compare the frequency of conflict events over time. Before we do, though, we need to preprocess the timestamps.\n\nacled_mya_sf &lt;- acled_mya_sf %&gt;% mutate(event_date=dmy(timestamp))\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `event_date = dmy(timestamp)`.\nCaused by warning:\n! All formats failed to parse. No formats found."
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#references",
    "href": "TakeHome/TakeHome1/take-home-1.html#references",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "References",
    "text": "References\n\nRaleigh, C., Kishi, R. & Linke, A. Political instability patterns are obscured by conflict dataset scope conditions, sources, and coding choices. Humanit Soc Sci Commun 10, 74 (2023). https://doi.org/10.1057/s41599-023-01559-4"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html",
    "href": "InClass/ICE4/in-class-4.html",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nSpatio-temporal point patterns analysis (STPPA) is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. Today’s exercise will use data on a real-world forest fire event in Kepulauan Bangka Belitung, Indonesia from 1st January to 31st December 2023, to illustrate the methods, procedures and interpretations of STPPA.\nThis chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire event in from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.1-overview-and-explanation",
    "href": "InClass/ICE4/in-class-4.html#ce4.1-overview-and-explanation",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nSpatio-temporal point patterns analysis (STPPA) is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. Today’s exercise will use data on a real-world forest fire event in Kepulauan Bangka Belitung, Indonesia from 1st January to 31st December 2023, to illustrate the methods, procedures and interpretations of STPPA.\nThis chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire event in from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.2-research-questions",
    "href": "InClass/ICE4/in-class-4.html#ce4.2-research-questions",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.2 Research questions",
    "text": "CE4.2 Research questions\nBy the end of the exercise I hope to find out:\n\nIf the locations of forest fires in Kepulauan Bangka Belitung are spatially and spatially-temporally independent, and;\nIf not, where and when the observed forest fire locations tend to cluster."
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.3-the-data",
    "href": "InClass/ICE4/in-class-4.html#ce4.3-the-data",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.3 The data",
    "text": "CE4.3 The data\n\nforestfires, a CSV file that provides locations on forest fires from Moderate Resolution Imaging Spectroradiometer (MODIS) sensor data.\nKepulauan_Bangka_Belitung, which as the name suggests marks the boundary of the region of Kepulauan Bangka Belitung."
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.4-new-r-packages",
    "href": "InClass/ICE4/in-class-4.html#ce4.4-new-r-packages",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.4 New R Packages",
    "text": "CE4.4 New R Packages\nA new R package to be introduced today is rgdal, which is used for importing geospatial data in the GIS file format and saving it as a Spatial* DataFrame.\nIn addition, sparr gives us the ability to estimate fixed and adatptive kernel-smoothed spatial relative risk surfaces via the density-ratio method, and perform subsequent inferrence.\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, sparr)"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.5-importing-and-preparing-study-area",
    "href": "InClass/ICE4/in-class-4.html#ce4.5-importing-and-preparing-study-area",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.5 Importing and preparing study area",
    "text": "CE4.5 Importing and preparing study area\n\nCE4.5.1 Importing study area and creating OWIN object\n\nkbb &lt;- st_read(dsn=\"data/rawdata\", layer=\"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop=TRUE, what=\"ZM\") %&gt;% # Drop Z-values\n  st_transform(crs=32748) # EPSG: Indonesia\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/Users/kendricktty/Gits/SMU_CS/is415-site/InClass/ICE4/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n# This dataset keeps Z-dimension (height) data. We might want to remove it if we are to do KDE\nkbb_owin &lt;- as.owin(kbb)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.5.1-importing-study-area",
    "href": "InClass/ICE4/in-class-4.html#ce4.5.1-importing-study-area",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.5.1 Importing study area",
    "text": "CE4.5.1 Importing study area\n\nkbb &lt;- st_read(dsn=\"data/rawdata\", layer=\"Kepulauan_Bangka_Belitung\")\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/Users/kendricktty/Gits/SMU_CS/is415-site/InClass/ICE4/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "InClass/ICE4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "InClass/ICE4/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415 - Kendrick",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.5.1-importing-study-area-and-convert-to-owin",
    "href": "InClass/ICE4/in-class-4.html#ce4.5.1-importing-study-area-and-convert-to-owin",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.5.1 Importing study area and convert to OWIN",
    "text": "CE4.5.1 Importing study area and convert to OWIN\n\nkbb &lt;- st_read(dsn=\"data/rawdata\", layer=\"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop=TRUE, what=\"ZM\") %&gt;% # Drop Z-values\n  st_transform(crs=32748) # EPSG: Indonesia\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/Users/kendricktty/Gits/SMU_CS/is415-site/InClass/ICE4/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n# This dataset keeps Z-dimension (height) data. We might want to remove it if we are to do KDE\nkbb_owin &lt;- as.owin(kbb)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.5.1-importing-study-area-and-creating-owin-object",
    "href": "InClass/ICE4/in-class-4.html#ce4.5.1-importing-study-area-and-creating-owin-object",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.5.1 Importing study area and creating OWIN object",
    "text": "CE4.5.1 Importing study area and creating OWIN object\n\nkbb &lt;- st_read(dsn=\"data/rawdata\", layer=\"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop=TRUE, what=\"ZM\") %&gt;% # Drop Z-values\n  st_transform(crs=32748) # EPSG: Indonesia\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/Users/kendricktty/Gits/SMU_CS/is415-site/InClass/ICE4/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n# This dataset keeps Z-dimension (height) data. We might want to remove it if we are to do KDE\nkbb_owin &lt;- as.owin(kbb)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;% st_as_sf(coords=c(\"longitude\", \"latitude\"), crs=4326) %&gt;% st_transform(crs=32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.6-importing-and-preparing-forest-fire-data",
    "href": "InClass/ICE4/in-class-4.html#ce4.6-importing-and-preparing-forest-fire-data",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.6 Importing and preparing forest fire data",
    "text": "CE4.6 Importing and preparing forest fire data\n\n# Creating an SF dataframe from a CSV removes \"longitude\" and \"latitude\", transforming it to a \"geometry\" field\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;% st_as_sf(coords=c(\"longitude\", \"latitude\"), crs=4326) %&gt;% st_transform(crs=32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe will want to convert our SF object into ppp, which only accepts numerical or character data, later on. We will therefore need to convert our acq_date fields into numeric fields.\n\nfire_sf &lt;- fire_sf %&gt;% mutate(DayOfYear=yday(acq_date)) %&gt;%\n                      mutate(Month_num=month(acq_date)) %&gt;%\n                      mutate(Month_fac=month(acq_date, label=TRUE, abbr=FALSE))"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.7-visualising-fire",
    "href": "InClass/ICE4/in-class-4.html#ce4.7-visualising-fire",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.7 Visualising fire",
    "text": "CE4.7 Visualising fire"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.7-visualising-fire-locations",
    "href": "InClass/ICE4/in-class-4.html#ce4.7-visualising-fire-locations",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.7 Visualising fire locations",
    "text": "CE4.7 Visualising fire locations\n\nCE4.7.1 As points\n\n# tm_shape(kbb) + tm_polygons() + tm_shape(fire_sf) + tm_dots()\ntm_shape(kbb) + tm_polygons() + tm_shape(fire_sf) + tm_bubbles()\n\n\n\n\n\n\n\n\n\n\nCE4.7.2 Over time\n\ntm_shape(kbb) + tm_polygons() + tm_shape(fire_sf) + tm_dots(size=0.1) + tm_facets(by=\"Month_fac\", free.coords=FALSE, drop.units=TRUE)\n\n\n\n\n\n\n\n# free.coords: All points have the same coordinate pairs"
  },
  {
    "objectID": "InClass/ICE4/in-class-4.html#ce4.8-computing-stkde-by-month",
    "href": "InClass/ICE4/in-class-4.html#ce4.8-computing-stkde-by-month",
    "title": "CE4/H4: Spatial-Temporal Point Patterns Analysis",
    "section": "CE4.8 Computing STKDE by Month",
    "text": "CE4.8 Computing STKDE by Month\nUsing sparttemp.density() of the sparr package, we are able to compute spatial-temporal KDE (STKDE).\n\nCE4.8.1 Forest fires by month (ppp)\n\nfire_month &lt;- fire_sf %&gt;% select(Month_num)\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\n\nCE4.8.2 Spatio-temporal KDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\n\nCE4.8.3 Plotting the spatio-temporal KDE object\nThis code chunk plot()s the KDE for the entire year 2023. As expected, the KDEs indicate far fewer occurrences of forest fires in the area before June 2023 and in December 2023 (the rainy season usually falls between December and February.)\n\n# sparr\ntims &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\npar(mfcol=c(1,2))\nfor (i in tims) {\n  plot(st_kde, i, override.par=FALSE, fix.range=TRUE, main=paste(\"KDE at month\", i))\n}"
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.3-importing-and-transforming-armed-conflict-data-and-administrative-boundary-data-into-sf-and-tibble-dataframes",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.3-importing-and-transforming-armed-conflict-data-and-administrative-boundary-data-into-sf-and-tibble-dataframes",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.3 Importing and transforming armed conflict data and administrative boundary data into sf and tibble dataframes",
    "text": "TH1.3 Importing and transforming armed conflict data and administrative boundary data into sf and tibble dataframes\n\nTH1.3.1 Loading R packages and aspatial data\nThe R packages we will use today are:\n\nsf\ntmap\nspatstat\nraster\nmaptools\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nacled_mya &lt;- read_csv(\"data/ACLED_Myanmar.csv\")\n\nRows: 47832 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(acled_mya)\n\n# A tibble: 6 × 31\n  event_id_cnty event_date        year time_precision disorder_type   event_type\n  &lt;chr&gt;         &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;     \n1 MMR56099      31 December 2023  2023              1 Political viol… Explosion…\n2 MMR56222      31 December 2023  2023              1 Political viol… Explosion…\n3 MMR56370      31 December 2023  2023              1 Political viol… Battles   \n4 MMR56376      31 December 2023  2023              1 Demonstrations  Protests  \n5 MMR56380      31 December 2023  2023              1 Strategic deve… Strategic…\n6 MMR56869      31 December 2023  2023              1 Strategic deve… Strategic…\n# ℹ 25 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, geo_precision &lt;dbl&gt;, source &lt;chr&gt;,\n#   source_scale &lt;chr&gt;, notes &lt;chr&gt;, fatalities &lt;dbl&gt;, tags &lt;chr&gt;,\n#   timestamp &lt;dbl&gt;\n\n\n\n\nTH1.3.2 Loading and plotting geospatial data\nThree representations of Myanmar’s geography exist on - Admin1 subdivides the country into its states and regions only, while Admin2 subdivides the country by its smaller districts, and Admin3 its townships. Further, the ACLED labels each incident with all 3 representations. For simplicity and ease of understanding, we shall use the Admin1 representation.\n\nmmr_admin1 &lt;- st_read(dsn = \"data/mmr_polbnda_adm1_250k_mimu_1\", layer = \"mmr_polbnda_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda_adm1_250k_mimu_1' from data source \n  `/Users/kendricktty/Gits/smu_cs/is415-site/TakeHome/TakeHome1/data/mmr_polbnda_adm1_250k_mimu_1' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nmmr_admin1\n\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID          ST ST_PCODE           ST_RG          ST_MMR PCode_V\n1         1  Ayeyarwady   MMR017          Region  ဧရာဝတီတိုင်းဒေသကြီး     9.4\n2         2        Bago   MMR111          Region    ပဲခူးတိုင်းဒေသကြီး     9.4\n3         4        Chin   MMR004           State       ချင်းပြည်နယ်     9.4\n4         5      Kachin   MMR001           State       ကချင်ပြည်နယ်     9.4\n5         6       Kayah   MMR002           State       ကယားပြည်နယ်     9.4\n6         7       Kayin   MMR003           State        ကရင်ပြည်နယ်     9.4\n7         8      Magway   MMR009          Region   မကွေးတိုင်းဒေသကြီး     9.4\n8         9    Mandalay   MMR010          Region မန္တလေးတိုင်းဒေသကြီး     9.4\n9        10         Mon   MMR011           State         မွန်ပြည်နယ်     9.4\n10       11 Nay Pyi Taw   MMR018 Union Territory        နေပြည်တော်     9.4\n                         geometry\n1  MULTIPOLYGON (((95.20798 15...\n2  MULTIPOLYGON (((96.17964 19...\n3  MULTIPOLYGON (((93.36931 24...\n4  MULTIPOLYGON (((97.59674 28...\n5  MULTIPOLYGON (((97.1759 19....\n6  MULTIPOLYGON (((97.81508 16...\n7  MULTIPOLYGON (((94.11699 22...\n8  MULTIPOLYGON (((96.14023 23...\n9  MULTIPOLYGON (((97.73689 15...\n10 MULTIPOLYGON (((96.32013 20...\n\nqtm(mmr_admin1)\n\n\n\n\n\n\n\n\n\n\nTH1.3.3 Creating sf data frame from aspatial data\nThe ACLED tibble contains coordinates, making it useful for plotting on our map as points. We can therefore use it to create an sf data frame using which we can plot our points on a map. The EPSG format of the import coordinates should be 4326, corresponding to the WGS84 Geographic Coordinate System.\n\nacled_mya_sf &lt;- st_as_sf(acled_mya, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nThe EPSG area code for Myanmar is 4239, while the WGS 84-compatible code is 32647. Since we’re creating an owin object later, we need to first convert our coordinate system.\n\nacled_mya_sf &lt;- acled_mya_sf %&gt;% st_transform(crs = 32647)\nmmr_admin1 &lt;- mmr_admin1 %&gt;% st_transform(crs = 32647)\ntm_shape(mmr_admin1) + tm_polygons() + tm_shape(acled_mya_sf) + tm_dots(size = 0.05)\n\n\n\n\n\n\n\n\nAdditionally, since the data is timestamped, we are able to plot and compare the frequency of conflict events over time. Before we do, though, we need to standardise the date stamps, then compartmentalise them into their year, month and day components, so that we can perform spatial-temporal point patterns analysis (STPPA) later.\nA visualisation of the spatial-temporial distribution of points can be found in Annex A. Notice the consistent appearance throughout the entire study period of a large cluster of points towards the west of the country - roughly the location of Rahkine state on the border with Bangladesh.\n\nacled_mya_sf &lt;- acled_mya_sf %&gt;%\n    mutate(event_date = dmy(event_date)) %&gt;%\n    mutate(DayOfYear = yday(event_date)) %&gt;%\n    mutate(Month_num = format(event_date, \"%Y-%m\")) %&gt;%  # Year-Month format\n    mutate(Month_fac = factor(format(event_date, \"%B %Y\"))) %&gt;% # Full month\n    mutate(Quarter = paste0(year(event_date), \"-\", quarter(event_date), \"Q\"))  # Quarter format\n\n\n\nTH1.3.4 Final steps to prepare for KDE\nFinally, before moving on to our KDE,\n\nTH1.3.4.1 Using owin to confine study area within Myanmar borders\n\nmmr_admin1_owin &lt;- as.owin(mmr_admin1)\nplot(mmr_admin1_owin)\n\n\n\n\n\n\n\n# summary(mmr_admin1_owin)\n\n\n\nTH1.3.4.2 Converting ACLED sf object to ppp for KDE\n\nacled_mya_ppp &lt;- as.ppp(acled_mya_sf)\n\nWarning in as.ppp.sf(acled_mya_sf): only first attribute column is used for\nmarks\n\nplot(acled_mya_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 47832 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\nacled_mya_ppp\n\nMarked planar point pattern: 47832 points\nmarks are of storage type  'character'\nwindow: rectangle = [-207135, 640934.5] x [1103500.1, 3042960.3] units\n\n\n\n\nTH1.3.4.3 Handling duplicates\nFirst, we check if there are duplicated points in the ACLED ppp.\n\nany(duplicated(acled_mya_ppp))\n\n[1] FALSE\n\nsum(multiplicity(acled_mya_ppp) &gt; 1)\n\n[1] 0\n\n\n\n\nTH1.3.4.4 Combining point events object and owin\n\nacled_mya_ppp = acled_mya_ppp[mmr_admin1_owin]\nplot(acled_mya_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 47825 symbols are shown in the symbol map"
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#annex-a-spatial-temporal-distribution-of-armed-conflict-occurrences-in-myanmar-between-2019-and-2023",
    "href": "TakeHome/TakeHome1/take-home-1.html#annex-a-spatial-temporal-distribution-of-armed-conflict-occurrences-in-myanmar-between-2019-and-2023",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "Annex A: Spatial-temporal distribution of armed conflict occurrences in Myanmar between 2019 and 2023",
    "text": "Annex A: Spatial-temporal distribution of armed conflict occurrences in Myanmar between 2019 and 2023\n\ntm_shape(mmr_admin1) + tm_polygons() + tm_shape(acled_mya_sf) + tm_dots(size = 0.1) + tm_facets(by=\"Quarter\", free.coords=FALSE, drop.units=TRUE, ncol=3, nrow=1)\n\n\n\n\n\n\n\n\n=======================\n\n\n\n\n\n\n\n\n\n===========\n\n\n\n\n\n\n\n\n\n============\n\n\n\n\n\n\n\n\n\n===========\n\n\n\n\n\n\n\n\n\n============\n\n\n\n\n\n\n\n\n\n==========="
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.4-interlude-a-brief-history-of-myanmars-ethnic-groups",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.4-interlude-a-brief-history-of-myanmars-ethnic-groups",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.4 Interlude: A brief history of Myanmar’s ethnic groups",
    "text": "TH1.4 Interlude: A brief history of Myanmar’s ethnic groups"
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.5-first-order-sppa",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.5-first-order-sppa",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.5 First Order SPPA",
    "text": "TH1.5 First Order SPPA"
  },
  {
    "objectID": "TakeHome/TakeHome1/take-home-1.html#th1.5-first-order-sppa---kde",
    "href": "TakeHome/TakeHome1/take-home-1.html#th1.5-first-order-sppa---kde",
    "title": "TH1: Geospatial Analytics for Social Good",
    "section": "TH1.5 First Order SPPA - KDE",
    "text": "TH1.5 First Order SPPA - KDE\nKernel density estimation (KDE) serves to compute the intensity of a point distribution. It has two general steps: first to compute the point intensity, followed by spatial interpolation using a kernel function.\n\n# Create a list to store KDE results and track quarters for each quarter\nkde_results &lt;- list()\nquarters &lt;- unique(acled_mya_ppp$Quarter)\nfor (quarter in quarters) {\n  acled_mya_quarters_subset &lt;- acled_mya_ppp[acled_mya_ppp$Quarter == quarter]\n  # Compute KDE and append to list\n  kde_results[[as.character(quarter)]] &lt;- density(acled_mya_quarters_subset)\n}"
  }
]