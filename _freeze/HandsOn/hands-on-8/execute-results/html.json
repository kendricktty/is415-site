{
  "hash": "26196a5b62ca50fbf14356bdc7b4435d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"HX8: Spatially Constrained Clustering Analysis\"\nsubtitle: \"Hands-On Exercise 8\"\nauthor: \"Kendrick Teo\"\ndate: \"2024-10-10\"\ndate-modified: \"last-modified\"\n\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n---\n\n\n\n## HX8.1 Overview\n\nThis hands-on exercise is a continuation of [Hands-on Exercise 7](hands-on-7.qmd), where the focus now will be on **spatially constrained clustering analysis**.\n\n## HX8.2 Loading R packages and preparing data\n\nIn this section, we will load the R packages and the data we need, which are the same as Hands-on Exercise 7. We will also replicate the steps from the earlier exercise to derive the penetration rate of various ICT device types.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n# Retrieve joined DF as saved in exercise 7\nshan_sf <- read_rds(\"data/rds/shan_sf.rds\")\nict <- read_csv (\"data/aspatial/Shan-ICT.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*100) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*100) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*100) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*100) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*100) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*100) %>%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`)\nsummary(ict_derived)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 2.105  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:13.895  \n Median : 3559   Median : 244.0   Median : 316.0   Median :21.095  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :21.568  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:26.807  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :48.452  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :11.60   Min.   : 0.278   Min.   : 3.642   Min.   :0.3278  \n 1st Qu.:45.02   1st Qu.: 2.284   1st Qu.:19.014   1st Qu.:1.1832  \n Median :51.72   Median : 3.759   Median :30.527   Median :1.8970  \n Mean   :50.95   Mean   : 5.109   Mean   :31.405   Mean   :2.4393  \n 3rd Qu.:60.64   3rd Qu.: 6.972   3rd Qu.:42.843   3rd Qu.:2.9897  \n Max.   :84.25   Max.   :18.149   Max.   :73.543   Max.   :9.2402  \n  INTERNET_PR     \n Min.   : 0.1041  \n 1st Qu.: 0.8617  \n Median : 2.2829  \n Mean   : 3.0644  \n 3rd Qu.: 4.1281  \n Max.   :11.7985  \n```\n\n\n:::\n:::\n\n\n\n### HX8.2.1 Abridged EDA\n\nAs a recap, we will also draw the choropleth maps and correlation matrix from the last exercise.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n## HX8.3 Spatially Constrained Clustering: SKATER approach\n\nThis section serves to derive spatially constrained clusters using the `skater()` function from the `spdep` package. The **SKATER** (**S**patial '**K**'luster **A**nalysis by **T**ree **E**dge **R**emoval) method builds off a connectivity *graph* representing spatial relationships between neighbouring areas. In this graph, each area is represented by a *node* and each *edge* represents a connection between areas. The dissimilarity between neighbouring areas constitutes the *edge costs*, and we reduce the graph by pruning edges with higher dissimilarity, until we are left with a **minimum spanning tree** - that is, a tree with $n$ nodes and $n - 1$ edges. Any further pruning would create **subgraphs**, which become our **cluster candidates**.\n\n### HX8.3.1 Converting to `SpatialPolygonsDataFrame`\n\nThe `skater()` function only supports `sp` objects, such as the `SpatialPolygonsDataFrame`. Hence, we need to convert `shan_sf` as needed first.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sp <- as_Spatial(shan_sf)\n```\n:::\n\n\n\n### HX8.3.2 Computing Neighbour List\n\nNext, `poly2nd()` from the `spdep` package will be used to compute the neighbours list from the polygon list.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.nb <- poly2nb(shan_sp)\nsummary(shan.nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n```\n\n\n:::\n:::\n\n\n\nWe can plot the neighbour list on `shan_sp` by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map.\n\nThe first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original `SpatialPolygonDataFrame` (*Shan* state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We can also specify `add=TRUE` to plot the network on top of the boundaries.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"red\", \n     add=TRUE)\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n> Note that if you plot the network first and then the boundaries, some areas will be clipped because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n## HX8.4 Creating connectivity graph\n\n### HX8.4.1 Calculating edge costs\n\n`nbcosts()` of `spdep` is used to compute the cost of each edge.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# From exercise 7\nshan_ict <- read_rds('data/rds/shan_ict.rds')\nlcosts <- nbcosts(shan.nb, shan_ict)\n```\n:::\n\n\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\n\nFollowing that, we will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights. In order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below. Note that we have to specify the style as `B` to make sure the cost values are not row-standardised.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.w <- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1      S2\nB 55 3025 7626.765 582607.8 5220160\n```\n\n\n:::\n:::\n\n\n\n## HX8.5 Computing minimum spanning tree\n\nIt is now time to create our minimum spanning tree. The tree is computed using the `mstree()` method of the `spdep` package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.mst <- mstree(shan.w)\n# Check class of shan.mst\nclass(shan.mst)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"mst\"    \"matrix\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check dimensions\ndim(shan.mst)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 54  3\n```\n\n\n:::\n:::\n\n\n\nNote that the dimension is **54** and not **55**. This is because the tree comprises $n-1$ *edges* (links) in order to traverse all the nodes.\n\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(shan.mst)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]      [,3]\n[1,]   19   39  7.941836\n[2,]   39   41 16.280878\n[3,]   41   27  7.829342\n[4,]   27   30  5.760801\n[5,]   30   51 10.837735\n[6,]   51   38 14.666661\n```\n\n\n:::\n:::\n\n\n\nWe can also plot our tree to show the observation numbers of each node in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"orange2\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## HX8.6 Computing spatially constrained clusters using SKATER method\n\nWe can now use the code chunk below to compute the spatially constrained clusters using `skater()` from `spdep`. `skater()` takes three mandatory arguments: the first two columns of the MST matrix (i.e. not the cost); the data matrix (to update the costs as units are being grouped), and; the number of cuts. The result of the skater() is an object of class skater, whose contents we can examine.\n\n> Note: The number of cuts is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclust6 <- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\nstr(clust6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 376\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 342\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 146\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 9.5\n  .. ..$ ssw : num 9.5\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 1261\n $ ssw         : num [1:6] 1261 1098 996 954 912 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n```\n\n\n:::\n:::\n\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitrary). This is followed by a detailed summary for each of the clusters in the `edges.groups` list. The sum of squares measures are given as `ssto` for the total and `ssw` to show the effect of each of the cuts on the overall criterion.\n\nGiven our clusters, we can print the cluster assignment, or use the `table()` function to find out the number of observations in each cluster. Parenthetially, we can also interpret the latter as the dimension of each vector in the lists contained in `edges.groups`. For example, the first list has node with dimension `12`, corresponding to the number of observations in the first cluster.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nccs6 <- clust6$groups\nccs6\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 3 3 6 3 3 3 3 3 3 3 1 2 2 2 1 2 2 2 1 4 2 1 5 2 2 2 1 2 1 1 2 1 1 2 2 3 2 1\n[39] 1 1 1 1 1 4 2 3 1 2 2 2 1 2 1 2 2\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(ccs6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nccs6\n 1  2  3  4  5  6 \n18 22 11  2  1  1 \n```\n\n\n:::\n:::\n\n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"yellow4\", \"purple\"),\n     cex.circles=0.005, \n     add=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n## HX8.7 Visualising clusters on choropleth map\n\nWe can now plot our newly derived clusters onto a map. For easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups_mat <- as.matrix(clust6$groups)\n# From exercise 7\nshan_sf_cluster <- read_rds('data/rds/shan_sf_cluster.rds')\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\n\nshclust.map <- qtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n# From exercise 7\nhclust.map <- read_rds('data/rds/hmap.rds')\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nThere is significantly less fragmentation in our SKATER-derived clusters map, and one would notice how the clusters in the map correspond with the graph from earlier.\n\n## HX8.8 Spatially Constrained Clustering: ClustGeo method\n\n### HX8.8.1 A short note about ClustGeo\n\nAs described in the course website (Kam, 2024):\n\n> ClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called `hclustgeo()` including spatial/geographical constraints.\n\n> In the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\n\n> The idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called `choicealpha()`.\n\n## HX8.8.2 Ward-like hierarchical clustering with ClustGeo\n\nThe `ClustGeo` package provides us with a function called `hclustgeo()` to perform Ward-like hierarchical clustering. To use this method to perform non-spatially-constrained hierarchical clustering, all we need to provide is a dissimilarity matrix - specifically, the one from Hands-on exercise 7.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# From hands-on exercise 7\nproxmat <- read_rds('data/rds/proxmat.rds')\nnongeo_cluster <- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n## HX8.8.3.1 Mapping the clusters formed\n\nThe ClustGeo clusters can also be plotted onto a map as follows.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups <- as.factor(cutree(nongeo_cluster, k=6))\nshan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n## HX8.9 Spatially-constrained hierarchical clustering\n\nBefore performing spatially constrained hierarchical clustering, we need to first construct a spatial distance matrix using `st_distance()` from the `sf` package. Notice that `as.dist()` is used to convert the data frame into matrix.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist <- st_distance(shan_sf, shan_sf)\ndistmat <- as.dist(dist)\n```\n:::\n\n\n\nNext, `choicealpha()` is used to determine a suitable value for the mixing parameter $\\alpha$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n:::\n\n\nWe will choose $\\alpha = 0.2$ as per the graphs above.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.2)\n```\n:::\n\n\n\nNext, `cutree()` is used to derive the cluster object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups <- as.factor(cutree(clustG, k=6))\n```\n:::\n\n\n\nFinally, we `cbind` the group list back to `shan_sf`, so that we can plot our newly delineated spatially constrained clusters.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\nqtm(shan_sf_Gcluster, \"CLUSTER\")\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n## HX8.10 Visual interpretation of clusters\n\n### HX8.10.1 Visualising individual clustering variable\n\nWe can use `ggplot` to plot the distribution of any clustering variable by cluster in a boxplot. In this example, we will plot the distribution of `RADIO_PR`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\nThe boxplot reveals cluster 3 displays the highest radio penetration rate on average, followed by clusters 2, 1, 4, 6 and 5.\n\n### HX8.10.2 Multivariate visualisation\n\nWe can also choose to create multiple parallel coordinate plots, which have been shown to reveal clustering variables extremely effectively. In the below code chunk, parallel coordinate plots can be created by means of `ggparcoord()` from the `GGally` package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n```\n\n::: {.cell-output-display}\n![](hands-on-8_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships have a higher rate of ICT device ownership, while those in cluster 5 have the lowest.\n\nOn the possible `scale` arguments for `ggparcoor()`, the course website notes:\n\n> Note that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\n> * std: univariately, subtract mean and divide by standard deviation.\n> * robust: univariately, subtract median and divide by median absolute deviation.\n> * uniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\n> * globalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\n> * center: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\n> * centerObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n> * There is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\n\n### HX8.10.3 Printing summary statistics\n\nThe following code chunk creates a summarised table for us to print summary statistics per cluster.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_ngeo_cluster %>% \n  st_set_geometry(NULL) %>%\n  group_by(CLUSTER) %>%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  <chr>           <dbl>      <dbl>           <dbl>          <dbl>\n1 1               22.1        52.1            4.42           24.6\n2 2               23.7        40.2            2.39           13.4\n3 3               30.0        61.1            5.22           39.2\n4 4               19.6        74.4            9.90           65.1\n5 5               12.4        22.4            3.80           13.2\n6 6                9.86       49.9            7.45           46.8\n# ℹ 1 more variable: mean_COMPUTER_PR <dbl>\n```\n\n\n:::\n:::\n\n\n\n## References\n\n1.  Kam, T. S. (2024). 12 Geographical Segmentation with Spatially Constrained Clustering Techniques. R for Geospatial Data Science and Analytics. <https://r4gdsa.netlify.app/chap12#correlation-analysis>",
    "supporting": [
      "hands-on-8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}